{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa53689",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:40.460283Z",
     "start_time": "2021-11-22T17:46:40.436804Z"
    }
   },
   "outputs": [],
   "source": [
    "versionString=\"25\"                                   # version string of this application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ca33c6",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## NanoDiP all-in-one Jupyter Notebook\n",
    "*J. Hench, S. Frank, and C. Hultschig, Neuropathology, IfP Basel, 2021*\n",
    "\n",
    "This software is provided free of charge and warranty; by using it you agree to do this on your own risk. The authors shall not be held liable for any damage caused by this software. We have assembled this and tested it to the best of our knowledge.\n",
    "\n",
    "The purpose of NanoDiP (Nanopore Digital Pathology) is to compare low-coverage Nanopore sequencing data from natively extracted DNA sequencing runs against a flexibly adaptable collection of 450K/850K Illumina Infinium Methylation array data. These data have to be preprocessed into binary beta value files; this operation is performed in R (uses minfi to read raw array data) and outputs bindary float files (one per dataset). These beta values files (e.g., 204949770141_R03C01_betas_filtered.bin) are named according to the array ID (Sentrix ID) followed by the suffix. A collection of betas_filtered.bin files can be provided in a static manner and XLSX (Microsoft Excel) tables can be used to select a subset thereof alongside a user-defined annotation. The corresponding datasets will be loaded into memory and then serve as the reference cohort to which the Nanopore data are compared by dimension reduction (UMAP). This comparison is optimized for speed and low resource consumption so that it can run on the computer that operates the sequencer. The sequencing run is initiated through the MinKNOW API by this application. Basecalling and methylation calling occur as background tasks outside this Jupyter Notebook. User interaction occurs through a web interface based on CherryPy which has been tested on Chromium web browser. It is advisable to run it locally, there are no measures to secure the generated website.\n",
    "\n",
    "In order to use this application properly please make sure to be somewhat familiar with Jupyter Notebook. To run the software, press the button called *restart the kernel, re-run the whole notebook (with dialog)* and confirm execution. Then, in Chromium Browser, navigate to http://localhost:8080/ and preferably bookmark this location for convenience. In case of errors, you may just again click the same button *restart the kernel, re-run the whole notebook (with dialog)*.\n",
    "___\n",
    "### Technical Details\n",
    "* Tested with Python 3.7.5; 3.8.8 fails to load minknow_api in jupyter notebook.\n",
    "* Verified to run on Ubuntu 18.04/Jetpack on ARMv8 and x86_64 CPUs; not tested on Windows and Mac OS. The latter two platforms are unsupported, we do not intend to support them.\n",
    "* **CAUTION**: Requires a *patched* version of minknow api, file `[VENV]/lib/python3.7/site-packages/minknow_api/tools/protocols.py`. Without the patch, the generated fast5 sequencing data will be unreadable with f5c or nanopolish (wrong compression algorithm, which is the default in the MinKNOW backend).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd526b10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:40.531516Z",
     "start_time": "2021-11-22T17:46:40.466411Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# verify running Python version (should be 3.7.5) and adjust jupyter notebook\n",
    "import IPython\n",
    "import os\n",
    "from IPython.core.display import display, HTML      # set display witdth to 100%\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "os.system('python --version')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3c8a03",
   "metadata": {},
   "source": [
    "## Multithreading Options\n",
    "Depending on the number of parallel threads/cores of the underlying hardware, threading options for multithreaded modules need to be set as environment-specific parameters. One way to do so is through the *os* module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270fada8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:40.555688Z",
     "start_time": "2021-11-22T17:46:40.539965Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# execution-wide multithreading options, set according to your hardware. Jetson AGX: suggest \"2\"\n",
    "# needs to be set before importing other modules that query these parameters\n",
    "import os\n",
    "os.environ[\"NUMBA_NUM_THREADS\"] = \"2\" # export NUMBA_NUM_THREADS=2\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f831a3",
   "metadata": {},
   "source": [
    "## Modules\n",
    "This section imports the required modules that should have been installed via pip. Other package managers have not been tested. To install packages, use the setup script provided with this software or, alternatively, install them one by one, ideally in a virtual python environment. Note that the MinKNOW API requires manual patching after installation with pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e69390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.289053Z",
     "start_time": "2021-11-22T17:46:40.562892Z"
    },
    "code_folding": [
     0
    ],
    "hide_input": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Python modules to load\n",
    "import argparse\n",
    "import cherrypy\n",
    "import datetime\n",
    "import fnmatch\n",
    "import logging\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from minknow_api.manager import Manager\n",
    "import minknow_api.statistics_pb2\n",
    "import minknow_api.device_pb2\n",
    "from minknow_api.tools import protocols\n",
    "from numba import jit\n",
    "import numpy\n",
    "import openpyxl\n",
    "import os\n",
    "from os import listdir\n",
    "import pandas\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import psutil\n",
    "import pysam\n",
    "import random\n",
    "import shutil\n",
    "import string\n",
    "import socket\n",
    "import subprocess\n",
    "import sys\n",
    "import time # for development purposes in jupyter notebook (progress bars)\n",
    "import timeit # benchmarking\n",
    "from tqdm.notebook import tqdm, trange # for development purposes in jupyter notebook (progress bars)\n",
    "#import umap # installed via pip install umap-learn; import moved to UMAP function\n",
    "import webbrowser\n",
    "from xhtml2pdf import pisa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13a13fc",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Below are system-specific parameters that may or may not require adaptation. Many variable names are be self-explanatory. The key difference between Nanopore setups are between devices provided by ONT (MinIT incl. running the MinIT distribution on a NVIDIA Jetson developer kit such as the AGX Xavier, GridION) and the typical Ubuntu-based MinKNOW version on x86_64 computers. The raw data are written into a `/data` directory on ONT-based devices while they are found in `/var/lib/minknow/data` on x86_64 installations. Make sure to adapt your `minknowDataDir` accordingly. There are furthermore permission issues and special folders / files in the MinKNOW data directory. These files / folders should be excluded from analysis through `fileHideList` so that only real run folders will be parsed. Finally, the `nanodipOutputDir` is the place in which the background methylation and alignment process will place its results by replicating the directory hierarchy of the MinKNOW data location. It will not duplicate the data, and these data will be much smaller than raw run data. They can be placed anywhere in the file tree, but also inside the MinKNOW data path within a sub-folder. If the latter is the case, make sure to apply appropriate read/write permissions. Final reports and figures generated by NanoDiP are written into `nanodipReportDir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bb346b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.324065Z",
     "start_time": "2021-11-22T17:46:46.295410Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# configuration parameters, modify here, no need for a configuration file\n",
    "minknowDataDir=\"/data\"                              # where MinKNOW places its data\n",
    "fileHideList=[\"pings\",                              # list of files and folders to be exluded from parsing\n",
    "              \"reads\",\"queued_reads\",\"core-dump-db\",\"lost+found\",\n",
    "              \"intermediate\",\n",
    "              \"minimap_data\",\"nanodip_tmp\",\"nanodip_output\",\n",
    "              \"nanodip_reports\",\n",
    "              \"non-ont\",\"raw_for_playback\",\"user_scripts\",\n",
    "              \"playback_raw_runs\",\".Trash-1000\"]\n",
    "nanodipOutputDir=\"/data/nanodip_output\"             # location to write intermediate analysis data, i.e. methylation and alignment files\n",
    "nanodipReportDir=\"/data/nanodip_reports\"            # location to write reports and figures\n",
    "readsPerFile=\"400\"                                  # number of reads per file. 400 works well on the Jetson AGX. Higher numbers increase batch size and RAM usage, lower numbers use more I/O resouces due to more frequent reloading of alignment reference\n",
    "wantedBases=150000000                               # number of basecalled bases until run termination occurs\n",
    "resultEndings=[\"_UMAP_top.html\",\"_UMAP_all.html\",   # list of file name sections that identify past runs\n",
    "               \"_NanoDiP_report.pdf\",\"_CNVplot.png\",\n",
    "               \"_NanoDiP_ranking.pdf\"]\n",
    "analysisExclude=[\"_TestRun_\"]                       # string patterns in sample names that exclude data from downstream analysis, e.g., test runs\n",
    "thisFaviconPath=\"/applications/nanodip/favicon.ico\" # the web browser favicon file for this application\n",
    "epidipLogoPath=\"/applications/nanodip/EpiDiP_Logo_01.png\" # logo bitmap for PDF reports\n",
    "imgPath=\"/applications/nanodip\"                     # the location where image files for the web application are stored\n",
    "cpgScriptPath=\"/applications/nanodip/calculate_overlap_CpGs_04.sh\" # script that loops over all fast5 folders, screens for predominant barcode and launched minimap2/f5c for each fast5 file \n",
    "thisHost=\"localhost\"                                # name of the host computer, typically \"localhost\"\n",
    "cherrypyHost=\"localhost\"                            # name of the host, typically \"localhost\" as well\n",
    "cherrypyPort=8080                                   # port on which the NanoDiP UI will be served\n",
    "cherrypyThreads=100                                 # number of concurrent threads allowed to CherryPy, decrease in case of performance problems, default = 100\n",
    "debugLogging=False                                  # CherryPy debug logging incl. access logs (True for testing only)\n",
    "binDir=\"/applications/reference_data/betaEPIC450Kmix_bin\" # location of the preprocessed beta value data\n",
    "binIndex=binDir+\"/index.csv\"                        # the index file of the beta value binary files is stored in a CSV files and is generated by the same R script that creates the beta value float binary files\n",
    "referenceDir=\"/applications/reference_data/reference_annotations\" # location of the XLSX files that contain annotations, i.e. reference file collection definitions\n",
    "methylCutOff=0.35                                   # cut-off for \"unmethylated vs methylated\" for Illumina array data; also applicable to other methylation data types\n",
    "topMatch=100                                        # number of reference cases to be shown in subplot including copy number profile links (not advisable >200, plotly will become really slow)\n",
    "cnvLinkPrefix=\"http://s1665.rootserver.io/umapplot01/\" # URL prefix to load PDF with CNV plot for a given Sentrix ID\n",
    "cnvLinkSuffix=\"_CNV_IFPBasel_annotations.pdf\"       # URL prefix to load PDF with CNV plot \n",
    "chrLengthsFile=\"/applications/reference_data/hg19_cnv/ChrLengths_hg19.tsv\"          # contains three columns, A:chrom. strings, B: chrom. lengths, C: offsets\n",
    "centromereLocationsBed=\"/applications/reference_data/hg19_cnv/hg19.centromere.bed\"  # contains the centromere positions for each chromosome\n",
    "plotlyRenderMode=\"webgl\"                            # default=\"webgl\", alternative \"svg\" without proper webgl support (e.g., firefox, use \"svg\"; slower, but does not require GPU)\n",
    "barcodeNames=[\"barcode01\",\"barcode02\",\"barcode03\",  # barcode strings, currently kit SQK-RBK004\n",
    "              \"barcode04\",\"barcode05\",\"barcode06\",\n",
    "              \"barcode07\",\"barcode08\",\"barcode09\",\n",
    "              \"barcode10\",\"barcode11\",\"barcode12\"]\n",
    "refgenomefa=\"/applications/reference_data/minimap_data/hg19.fa\" # human reference genome\n",
    "refgenomemmi=\"/applications/reference_data/minimap_data/hg19_nanodip.mmi\" # human reference genome minimap2 mmi\n",
    "ilmncgmapfile=\"/applications/reference_data/microarray/hg19_HumanMethylation450_15017482_v1-2_cgmap.tsv\" # Illumina probe names of the 450K array\n",
    "f5cBin=\"/applications/f5c/f5c\"                      # f5c binary location (absolute path) v6\n",
    "minimap2Bin=\"/applications/nanopolish/minimap2/minimap2\" # minimap2 binary location (absolute path)\n",
    "samtoolsBin=\"/applications/samtools/samtools\"       # samtools binary location (absolute path)\n",
    "rscriptBin=\"/applications/R-4.0.3/bin/Rscript\"      # Rscript binary location (absolute path)\n",
    "readCpGscript=\"/applications/nanodip/readCpGs_mod02.R\" # R script that reads CpGs into simplified text file (absolute path)\n",
    "verbosity=0                                         # 0=low log verbosity, 1=high log verbosity (with timestamps, for benchmarking and debugging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326eb9af",
   "metadata": {},
   "source": [
    "# No user editable code below\n",
    "Do not modify the cells below unless you would like to patch errors or create something new.\n",
    "## Sections\n",
    "1. Generic Functions\n",
    "2. MinKNOW API Functions\n",
    "3. CNV Plotter\n",
    "4. UMAP Methylation Plotter\n",
    "5. User Interface Functions\n",
    "6. Report Generator\n",
    "7. CherryPy Web UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a718d8cf",
   "metadata": {},
   "source": [
    "### 1. Generic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe86111",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.342449Z",
     "start_time": "2021-11-22T17:46:46.328833Z"
    },
    "code_folding": [
     0
    ],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def logpr(v,logstring): # logging funcion that reads verbosity parameter\n",
    "    if v==1:\n",
    "        print(str(datetime.datetime.now())+\": \"+str(logstring))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f5a0be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.352411Z",
     "start_time": "2021-11-22T17:46:46.346924Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def restartNanoDiP():\n",
    "    cherrypy.engine.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58560a33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.368415Z",
     "start_time": "2021-11-22T17:46:46.357332Z"
    },
    "code_folding": [
     0
    ],
    "hide_input": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def getRuns(): # lists run folders from MinKNOW data directory in reverse order based on modif. date\n",
    "    runFolders=[]\n",
    "    #runFolderDates=[]\n",
    "    for r in listdir(minknowDataDir):\n",
    "        if r not in fileHideList:\n",
    "            f=minknowDataDir+\"/\"+r\n",
    "            if os.path.isdir(f):\n",
    "                runFolders.append([r,float(os.path.getmtime(f))])\n",
    "    runFolders.sort(key=lambda row: (row[1], row[0]), reverse=True) # sort based on modif. date\n",
    "    runFolders=[j.pop(0) for j in runFolders] # remove date column after sorting\n",
    "    return(runFolders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbbe61e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.388722Z",
     "start_time": "2021-11-22T17:46:46.375592Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getPredominantBarcode(sampleName):\n",
    "    fast5List = [os.path.join(dp, f) for dp, dn, filenames in os.walk(minknowDataDir+\"/\"+sampleName) for f in filenames if os.path.splitext(f)[1] == '.fast5']\n",
    "    barcodeHits=[]\n",
    "    for b in range(len(barcodeNames)):\n",
    "        c=0\n",
    "        for f in fast5List:\n",
    "            if barcodeNames[b] in f:\n",
    "                c+=1\n",
    "        barcodeHits.append(c)\n",
    "    maxbarcode=max(barcodeHits)\n",
    "    if maxbarcode>1:\n",
    "        predominantBarcode=barcodeNames[barcodeHits.index(maxbarcode)]\n",
    "    else:\n",
    "        predominantBarcode=\"undetermined\"\n",
    "    return predominantBarcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d6c898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.403158Z",
     "start_time": "2021-11-22T17:46:46.393449Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def datetimestringnow(): # get current date and time as string to create timestamps\n",
    "    now = datetime.datetime.now()\n",
    "    return str(now.year).zfill(4)+str(now.month).zfill(2)+str(now.day).zfill(2)+\"_\"+str(now.hour).zfill(2)+str(now.minute).zfill(2)+str(now.second).zfill(2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9a0158",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.416361Z",
     "start_time": "2021-11-22T17:46:46.407606Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def convert_html_to_pdf(source_html, output_filename): # generate reports\n",
    "    result_file = open(output_filename, \"w+b\")         # open output file for writing (truncated binary)\n",
    "    pisa_status = pisa.CreatePDF(                      # convert HTML to PDF\n",
    "            source_html,                               # the HTML to convert\n",
    "            dest=result_file)                          # file handle to recieve result\n",
    "    result_file.close()                                # close output file\n",
    "    return pisa_status.err                            # return True on success and False on errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddca5938",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.428675Z",
     "start_time": "2021-11-22T17:46:46.419900Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getReferenceAnnotations(): # list all reference annotation files (MS Excel XLSX format)\n",
    "    referenceAnnotations=[]\n",
    "    for r in listdir(referenceDir):\n",
    "        if r.endswith('.xlsx'):\n",
    "            referenceAnnotations.append(r)    \n",
    "    return referenceAnnotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52e987d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.441796Z",
     "start_time": "2021-11-22T17:46:46.432336Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def writeReferenceDefinition(sampleId,referenceFile): # write the filename of the UMAP reference for the \n",
    "    with open(nanodipReportDir+'/'+sampleId+'_selected_reference.txt', 'w') as f: # current run into a text file\n",
    "        f.write(referenceFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fced958",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.457561Z",
     "start_time": "2021-11-22T17:46:46.446618Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def readReferenceDefinition(sampleId): # read the filename of the UMAP reference for the current sample\n",
    "    try:\n",
    "        with open(nanodipReportDir+'/'+sampleId+'_selected_reference.txt', 'r') as f:\n",
    "            referenceFile=f.read()\n",
    "    except:\n",
    "        referenceFile=\"\"\n",
    "    return referenceFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cd3df9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.474688Z",
     "start_time": "2021-11-22T17:46:46.462623Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def writeRunTmpFile(sampleId,deviceId):\n",
    "    with open(nanodipReportDir+'/'+sampleId+'_'+deviceId+'_runinfo.tmp', 'a') as f: # current run into a text file\n",
    "        try:\n",
    "            runId=getActiveRun(deviceId)\n",
    "        except:\n",
    "            runId=\"none\"\n",
    "        ro=getThisRunOutput(deviceId,sampleId,runId)\n",
    "        readCount=ro[0]\n",
    "        bascalledBases=ro[1]\n",
    "        overlapCpGs=getOverlapCpGs(sampleId)\n",
    "        f.write(str(int(time.time()))+\"\\t\"+\n",
    "                str(readCount)+\"\\t\"+\n",
    "                str(bascalledBases)+\"\\t\"+\n",
    "                str(overlapCpGs)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fce995",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.485725Z",
     "start_time": "2021-11-22T17:46:46.478685Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def readRunTmpFile(sampleId):\n",
    "    print(\"readRunTmpFile not ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d1aaef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.503910Z",
     "start_time": "2021-11-22T17:46:46.490199Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def getOverlapCpGs(sampleName):\n",
    "    methoverlapPath=nanodipOutputDir+\"/\"+sampleName # collect matching CpGs from sample\n",
    "    methoverlapTsvFiles=[] # find all *methoverlap.tsv files\n",
    "    for root, dirnames, filenames in os.walk(methoverlapPath):\n",
    "        for filename in fnmatch.filter(filenames, '*methoverlap.tsv'):\n",
    "            methoverlapTsvFiles.append(os.path.join(root, filename))\n",
    "    methoverlap=[]\n",
    "    first=True\n",
    "    for f in methoverlapTsvFiles:\n",
    "        try: # some fast5 files do not contain any CpGs\n",
    "            m=pandas.read_csv(f, delimiter='\\t', header=None, index_col=0)\n",
    "            if first:\n",
    "                methoverlap=m\n",
    "                first=False\n",
    "            else:\n",
    "                methoverlap=methoverlap.append(m)\n",
    "        except:\n",
    "            logpr(verbosity,\"empty file encountered, skipping\")\n",
    "    return len(methoverlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ec61b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.556199Z",
     "start_time": "2021-11-22T17:46:46.507913Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def f5cOneFast5(sampleId,analyzeOne=True):\n",
    "    analyzedCount=0\n",
    "    thisRunDir=minknowDataDir+\"/\"+sampleId\n",
    "    pattern = '*.fast5'\n",
    "    fileList = []\n",
    "    for dName, sdName, fList in os.walk(thisRunDir): # Walk through directory\n",
    "        for fileName in fList:\n",
    "            if fnmatch.fnmatch(fileName, pattern): # Match search string\n",
    "                fileList.append(os.path.join(dName, fileName))\n",
    "    calledList=[]\n",
    "    completedCount=0\n",
    "    maxBcCount=1 # at least 2 \"passed\" files (>1) need to be present\n",
    "    targetBc=\"undetermined\"\n",
    "    for bc in barcodeNames:\n",
    "        thisBc=0\n",
    "        for f in fileList:\n",
    "            if bc in f:\n",
    "                if \"_pass_\" in f:\n",
    "                    thisBc+=1\n",
    "        if thisBc > maxBcCount:\n",
    "            maxBcCount=thisBc\n",
    "            targetBc=bc\n",
    "    f5cAnalysisDir=nanodipOutputDir+\"/\"+sampleId\n",
    "    if os.path.exists(f5cAnalysisDir)==False:\n",
    "        os.mkdir(f5cAnalysisDir)\n",
    "    thisBcFast5=[]\n",
    "    thisBcFastq=[]\n",
    "    for f in fileList:\n",
    "        if targetBc in f:\n",
    "            q=f.replace(\".fast5\",\"\").replace(\"fast5_pass\",\"fastq_pass\")+\".fastq\"\n",
    "            if os.path.exists(q): # check if accompanying fastq exists\n",
    "                thisBcFast5.append(f)\n",
    "                thisBcFastq.append(q)\n",
    "                thisBcFileName=f.split(\"/\")\n",
    "                thisBcFileName=thisBcFileName[len(thisBcFileName)-1].replace(\".fast5\",\"\") # get name prefix (to be the analysis subdir name later)\n",
    "                thisAnalysisDir=f5cAnalysisDir+\"/\"+thisBcFileName\n",
    "                if os.path.exists(thisAnalysisDir)==False:\n",
    "                    os.mkdir(thisAnalysisDir)\n",
    "                target5=thisAnalysisDir+\"/\"+thisBcFileName+\".fast5\"\n",
    "                targetq=thisAnalysisDir+\"/\"+thisBcFileName+\".fastq\"\n",
    "                if os.path.exists(target5)==False:\n",
    "                    os.symlink(f,target5)             # fast5 symlink\n",
    "                if os.path.exists(targetq)==False:\n",
    "                    os.symlink(q,targetq)             #fastq symlink\n",
    "                if os.path.exists(thisAnalysisDir+\"/\"+thisBcFileName+\"-methoverlapcount.txt\")==False:\n",
    "                    if (analyzeOne==True and analyzedCount==0) or analyzeOne==False:\n",
    "                        cmd=f5cBin+\" index -t 1 --iop 100 -d \"+thisAnalysisDir+\" \"+targetq\n",
    "                        p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) #index, call methylation and get methylation frequencies\n",
    "                        p.wait()\n",
    "                        cmd=minimap2Bin+\" -a -x map-ont \"+refgenomemmi+\" \"+targetq+\" -t 4 | \"+samtoolsBin+\" sort -T tmp -o \"+thisAnalysisDir+\"/\"+thisBcFileName+\"-reads_sorted.bam\"\n",
    "                        p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) # get sorted BAM (4 threads)\n",
    "                        p.wait()\n",
    "                        cmd=samtoolsBin+\" index \"+thisAnalysisDir+\"/\"+thisBcFileName+\"-reads_sorted.bam\"\n",
    "                        p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) # index BAM\n",
    "                        p.wait()\n",
    "                        cmd=f5cBin+\" call-methylation -B2000000 -K400 -b \"+thisAnalysisDir+\"/\"+thisBcFileName+\"-reads_sorted.bam -g \"+refgenomefa+\" -r \"+targetq+\" > \"+thisAnalysisDir+\"/\"+thisBcFileName+\"-result.tsv\"\n",
    "                        p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) # set B to 2 megabases (GPU) and 0.4 kreads\n",
    "                        p.wait()\n",
    "                        cmd=f5cBin+\" meth-freq -c 2.5 -s -i \"+thisAnalysisDir+\"/\"+thisBcFileName+\"-result.tsv > \"+thisAnalysisDir+\"/\"+thisBcFileName+\"-freq.tsv\"\n",
    "                        p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)\n",
    "                        p.wait()\n",
    "                        cmd=rscriptBin+\" \"+readCpGscript+\" \"+thisAnalysisDir+\"/\"+thisBcFileName+\"-freq.tsv \"+ilmncgmapfile+\" \"+thisAnalysisDir+\"/\"+thisBcFileName+\"-methoverlap.tsv \"+thisAnalysisDir+\"/\"+thisBcFileName+\"-methoverlapcount.txt\"\n",
    "                        p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)\n",
    "                        p.wait()\n",
    "                        calledList.append(thisBcFileName)\n",
    "                        analyzedCount+=1\n",
    "                else:\n",
    "                    completedCount+=1\n",
    "    return \"Target = \"+targetBc+\"<br>Methylation called for \"+str(calledList)+\". \"+str(completedCount+analyzedCount)+\"/\"+str(len(thisBcFast5))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede7d7c7",
   "metadata": {},
   "source": [
    "### 2. MinKNOW API Functions\n",
    "Check https://github.com/nanoporetech/minknow_api for reference.\n",
    "\n",
    "The following code requires a patched version of the MinKNOW API, install it from https://github.com/neuropathbasel/minknow_api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced11ce9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.570173Z",
     "start_time": "2021-11-22T17:46:46.561610Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def mkManager(): # Construct a manager using the host + port provided. This is used to connect to\n",
    "    return Manager(host=thisHost, port=9501, use_tls=False) # the MinKNOW service trough the MK API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02565945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.585567Z",
     "start_time": "2021-11-22T17:46:46.575683Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def listMinionPositions(): # list MinION devices that are currenty connected to the system \n",
    "    manager = mkManager()\n",
    "    positions = manager.flow_cell_positions() # Find a list of currently available sequencing positions.  \n",
    "    return(positions)   # User could call {pos.connect()} here to connect to the running MinKNOW instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33075d65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.615199Z",
     "start_time": "2021-11-22T17:46:46.593539Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def listMinionExperiments(): # list all current and previous runs in the MinKNOW buffer, lost after MinKNOW restart\n",
    "    manager=mkManager()\n",
    "    htmlHost=\"<b>Host: \"+thisHost+\"</b><br><table border='1'><tr>\"\n",
    "    positions=manager.flow_cell_positions() # Find a list of currently available sequencing positions. \n",
    "    htmlPosition=[]\n",
    "    for p in positions:\n",
    "        htmlPosinfo=\"<b>-\"+str(p)+\"</b><br>\"\n",
    "        connection = p.connect()\n",
    "        mountedFlowCellID=connection.device.get_flow_cell_info().flow_cell_id # return the flow cell info\n",
    "        htmlPosinfo=htmlPosinfo+\"--mounted flow cell ID: <b>\" + mountedFlowCellID +\"</b><br>\"\n",
    "        htmlPosinfo=htmlPosinfo+\"---\"+str(connection.acquisition.current_status())+\"<br>\" # READY, STARTING, sequencing/mux = PROCESSING, FINISHING; Pause = PROCESSING\n",
    "        protocols = connection.protocol.list_protocol_runs()\n",
    "        bufferedRunIds = protocols.run_ids\n",
    "        for b in bufferedRunIds:\n",
    "            htmlPosinfo=htmlPosinfo+\"--run ID: \" + b +\"<br>\"\n",
    "            run_info = connection.protocol.get_run_info(run_id=b)\n",
    "            htmlPosinfo=htmlPosinfo+\"---with flow cell ID: \" + run_info.flow_cell.flow_cell_id +\"<br>\"\n",
    "        htmlPosition.append(htmlPosinfo)\n",
    "    hierarchy = htmlHost\n",
    "    for p in htmlPosition:\n",
    "        hierarchy=hierarchy + \"<td valign='top'><tt>\"+p+\"</tt></td>\"\n",
    "    hierarchy=hierarchy+\"</table>\"\n",
    "    return(hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d916592e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.633738Z",
     "start_time": "2021-11-22T17:46:46.621536Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getFlowCellID(thisDeviceId): # determine flow cell ID (if any). Note that some CTCs have an empty ID string.\n",
    "    mountedFlowCellID=\"no_flow_cell\"\n",
    "    manager=mkManager()\n",
    "    positions=manager.flow_cell_positions() # Find a list of currently available sequencing positions.\n",
    "    for p in positions:\n",
    "        if thisDeviceId in str(p):\n",
    "            connection = p.connect()\n",
    "            mountedFlowCellID=connection.device.get_flow_cell_info().flow_cell_id # return the flow cell info\n",
    "    return mountedFlowCellID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9229f4b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.765764Z",
     "start_time": "2021-11-22T17:46:46.643311Z"
    },
    "code_folding": [
     0
    ],
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# This cell starts a run on Mk1b devices and perform several checks concerning the run protocol.\n",
    "\n",
    "# modified from the MinKNOW API on https://github.com/nanoporetech/minknow_api (2021-06)\n",
    "# created from the sample code at\n",
    "# https://github.com/nanoporetech/minknow_api/blob/master/python/examples/start_protocol.py\n",
    "# minknow_api.manager supplies \"Manager\" a wrapper around MinKNOW's Manager gRPC API with utilities\n",
    "# for querying sequencing positions + offline basecalling tools.\n",
    "# from minknow_api.manager import Manager\n",
    "\n",
    "# We need `find_protocol` to search for the required protocol given a kit + product code.\n",
    "# from minknow_api.tools import protocols\n",
    "def parse_args():\n",
    "    \"\"\"Build and execute a command line argument for starting a protocol.\n",
    "\n",
    "    Returns:\n",
    "        Parsed arguments to be used when starting a protocol.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"\"\"\n",
    "        Run a sequencing protocol in a running MinKNOW instance.\n",
    "        \"\"\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--host\",\n",
    "        default=\"localhost\",\n",
    "        help=\"IP address of the machine running MinKNOW (defaults to localhost)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--port\",\n",
    "        help=\"Port to connect to on host (defaults to standard MinKNOW port based on tls setting)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--no-tls\", help=\"Disable tls connection\", default=False, action=\"store_true\"\n",
    "    )\n",
    "    parser.add_argument(\"--verbose\", action=\"store_true\", help=\"Enable debug logging\")\n",
    "\n",
    "    parser.add_argument(\"--sample-id\", help=\"sample ID to set\")\n",
    "    parser.add_argument(\n",
    "        \"--experiment-group\",\n",
    "        \"--group-id\",\n",
    "        help=\"experiment group (aka protocol group ID) to set\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--position\",\n",
    "        help=\"position on the machine (or MinION serial number) to run the protocol at\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--flow-cell-id\",\n",
    "        metavar=\"FLOW-CELL-ID\",\n",
    "        help=\"ID of the flow-cell on which to run the protocol. (specify this or --position)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--kit\",\n",
    "        required=True,\n",
    "        help=\"Sequencing kit used with the flow-cell, eg: SQK-LSK108\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--product-code\",\n",
    "        help=\"Override the product-code stored on the flow-cell and previously user-specified\"\n",
    "        \"product-codes\",\n",
    "    )\n",
    "    # BASECALL ARGUMENTS\n",
    "    parser.add_argument(\n",
    "        \"--basecalling\",\n",
    "        action=\"store_true\",\n",
    "        help=\"enable base-calling using the default base-calling model\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--basecall-config\",\n",
    "        help=\"specify the base-calling config and enable base-calling\",\n",
    "    )\n",
    "    # BARCODING ARGUMENTS\n",
    "    parser.add_argument(\n",
    "        \"--barcoding\", action=\"store_true\", help=\"protocol uses barcoding\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--barcode-kits\",\n",
    "        nargs=\"+\",\n",
    "        help=\"bar-coding expansion kits used in the experiment\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--trim-barcodes\", action=\"store_true\", help=\"enable bar-code trimming\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--barcodes-both-ends\",\n",
    "        action=\"store_true\",\n",
    "        help=\"bar-code filtering (both ends of a strand must have a matching barcode)\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--detect-mid-strand-barcodes\",\n",
    "        action=\"store_true\",\n",
    "        help=\"bar-code filtering for bar-codes in the middle of a strand\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--min-score\",\n",
    "        type=float,\n",
    "        default=0.0,\n",
    "        help=\"read selection based on bar-code accuracy\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--min-score-rear\",\n",
    "        type=float,\n",
    "        default=0.0,\n",
    "        help=\"read selection based on bar-code accuracy\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--min-score-mid\",\n",
    "        type=float,\n",
    "        default=0.0,\n",
    "        help=\"read selection based on bar-code accuracy\",\n",
    "    )\n",
    "    # ALIGNMENT ARGUMENTS\n",
    "    parser.add_argument(\n",
    "        \"--alignment-reference\",\n",
    "        help=\"Specify alignment reference to send to basecaller for live alignment.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--bed-file\", help=\"Specify bed file to send to basecaller.\",\n",
    "    )\n",
    "    # Output arguments\n",
    "    parser.add_argument(\n",
    "        \"--fastq\",\n",
    "        action=\"store_true\",\n",
    "        help=\"enables FastQ file output, defaulting to 4000 reads per file\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fastq-reads-per-file\",\n",
    "        type=int,\n",
    "        default=4000,\n",
    "        help=\"set the number of reads combined into one FastQ file.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fast5\",\n",
    "        action=\"store_true\",\n",
    "        help=\"enables Fast5 file output, defaulting to 4000 reads per file, this will store raw, \"\n",
    "        \"fastq and trace-table data\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fast5-reads-per-file\",\n",
    "        type=int,\n",
    "        default=4000,\n",
    "        help=\"set the number of reads combined into one Fast5 file.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--bam\",\n",
    "        action=\"store_true\",\n",
    "        help=\"enables BAM file output, defaulting to 4000 reads per file\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--bam-reads-per-file\",\n",
    "        type=int,\n",
    "        default=4000,\n",
    "        help=\"set the number of reads combined into one BAM file.\",\n",
    "    )\n",
    "    # Read until\n",
    "    parser.add_argument(\n",
    "        \"--read-until-reference\", type=str, help=\"Reference file to use in read until\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--read-until-bed-file\", type=str, help=\"Bed file to use in read until\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--read-until-filter\",\n",
    "        type=str,\n",
    "        choices=[\"deplete\", \"enrich\"],\n",
    "        help=\"Filter type to use in read until\",\n",
    "    )\n",
    "    # Experiment\n",
    "    parser.add_argument(\n",
    "        \"--experiment-duration\",\n",
    "        type=float,\n",
    "        default=72,\n",
    "        help=\"time spent sequencing (in hours)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--no-active-channel-selection\",\n",
    "        action=\"store_true\",\n",
    "        help=\"allow dynamic selection of channels to select pores for sequencing, \"\n",
    "        \"ignored for Flongle flow-cells\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--mux-scan-period\",\n",
    "        type=float,\n",
    "        default=1.5,\n",
    "        help=\"number of hours before a mux scan takes place, enables active-channel-selection, \"\n",
    "        \"ignored for Flongle flow-cells\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"extra_args\",\n",
    "        metavar=\"ARGS\",\n",
    "        nargs=\"*\",\n",
    "        help=\"Additional arguments passed verbatim to the protocol script\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    # Further argument checks\n",
    "    # Read until must have a reference and a filter type, if enabled:\n",
    "    if (\n",
    "        args.read_until_filter is not None\n",
    "        or args.read_until_reference is not None\n",
    "        or args.read_until_bed_file is not None\n",
    "    ):\n",
    "        if args.read_until_filter is None:\n",
    "            print(\"Unable to specify read until arguments without a filter type.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        if args.read_until_reference is None:\n",
    "            print(\"Unable to specify read until arguments without a reference type.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    if args.bed_file and not args.alignment_reference:\n",
    "        print(\"Unable to specify `--bed-file` without `--alignment-reference`.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    if (args.barcoding or args.barcode_kits) and not (\n",
    "        args.basecalling or args.basecall_config\n",
    "    ):\n",
    "        print(\n",
    "            \"Unable to specify `--barcoding` or `--barcode-kits` without `--basecalling`.\"\n",
    "        )\n",
    "        sys.exit(1)\n",
    "    if args.alignment_reference and not (args.basecalling or args.basecall_config):\n",
    "        print(\"Unable to specify `--alignment-reference` without `--basecalling`.\")\n",
    "        \n",
    "        sys.exit(1)\n",
    "    if not (args.fast5 or args.fastq):\n",
    "        print(\"No output (fast5 or fastq) specified\")\n",
    "\n",
    "    return args\n",
    "\n",
    "def is_position_selected(position, args):\n",
    "    \"\"\"Find if the {position} is selected by command line arguments {args}.\"\"\"\n",
    "\n",
    "    # First check for name match:\n",
    "    if args.position == position.name:\n",
    "        return True\n",
    "\n",
    "    # Then verify if the flow cell matches:\n",
    "    connected_position = position.connect()\n",
    "    if args.flow_cell_id is not None:\n",
    "        flow_cell_info = connected_position.device.get_flow_cell_info()\n",
    "        if (\n",
    "            flow_cell_info.user_specified_flow_cell_id == args.flow_cell_id\n",
    "            or flow_cell_info.flow_cell_id == args.flow_cell_id\n",
    "        ):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def startRun():\n",
    "    \"\"\"Entrypoint to start protocol example\"\"\"\n",
    "    # Parse arguments to be passed to started protocols:\n",
    "    run_id=\"\"\n",
    "    args = parse_args()\n",
    "    #args = parse_args(minknowApiShellArgumentString.split())\n",
    "\n",
    "    # Specify --verbose on the command line to get extra details about\n",
    "    if args.verbose:\n",
    "        logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "\n",
    "    # Construct a manager using the host + port provided:\n",
    "    #manager = Manager(host=args.host, port=args.port, use_tls=not args.no_tls)\n",
    "    manager=mkManager()\n",
    "    errormessage=\"\"\n",
    "    \n",
    "    # Find which positions we are going to start protocol on:\n",
    "    positions = manager.flow_cell_positions()\n",
    "    filtered_positions = list(\n",
    "        filter(lambda pos: is_position_selected(pos, args), positions)\n",
    "    )\n",
    "\n",
    "    # At least one position needs to be selected:\n",
    "    if not filtered_positions:\n",
    "        errormessage=\"No positions selected for protocol - specify `--position` or `--flow-cell-id`\"\n",
    "    else:\n",
    "        protocol_identifiers = {}\n",
    "        for pos in filtered_positions:\n",
    "            # Connect to the sequencing position:\n",
    "            position_connection = pos.connect()\n",
    "\n",
    "            # Check if a flowcell is available for sequencing\n",
    "            flow_cell_info = position_connection.device.get_flow_cell_info()\n",
    "            if not flow_cell_info.has_flow_cell:\n",
    "                errormessage=\"No flow cell present in position \"+str(pos)\n",
    "            else:\n",
    "                # Select product code:\n",
    "                if args.product_code:\n",
    "                    product_code = args.product_code\n",
    "                else:\n",
    "                    product_code = flow_cell_info.user_specified_product_code\n",
    "                    if not product_code:\n",
    "                        product_code = flow_cell_info.product_code\n",
    "\n",
    "                # Find the protocol identifier for the required protocol:\n",
    "                protocol_info = protocols.find_protocol(\n",
    "                    position_connection,\n",
    "                    product_code=product_code,\n",
    "                    kit=args.kit,\n",
    "                    basecalling=args.basecalling,\n",
    "                    basecall_config=args.basecall_config,\n",
    "                    barcoding=args.barcoding,\n",
    "                    barcoding_kits=args.barcode_kits,\n",
    "                )\n",
    "\n",
    "                if not protocol_info:\n",
    "                    print(\"Failed to find protocol for position %s\" % (pos.name))\n",
    "                    print(\"Requested protocol:\")\n",
    "                    print(\"  product-code: %s\" % args.product_code)\n",
    "                    print(\"  kit: %s\" % args.kit)\n",
    "                    print(\"  basecalling: %s\" % args.basecalling)\n",
    "                    print(\"  basecall_config: %s\" % args.basecall_config)\n",
    "                    print(\"  barcode-kits: %s\" % args.barcode_kits)\n",
    "                    print(\"  barcoding: %s\" % args.barcoding)\n",
    "                    errormessage=\"Protocol build error, consult application log.\"\n",
    "                else:\n",
    "                    # Store the identifier for later:\n",
    "                    protocol_identifiers[pos.name] = protocol_info.identifier\n",
    "\n",
    "                    # Start protocol on the requested postitions:\n",
    "                    print(\"Starting protocol on %s positions\" % len(filtered_positions))\n",
    "                    for pos in filtered_positions:\n",
    "\n",
    "                        # Connect to the sequencing position:\n",
    "                        position_connection = pos.connect()\n",
    "\n",
    "                        # Find the protocol identifier for the required protocol:\n",
    "                        protocol_identifier = protocol_identifiers[pos.name]\n",
    "\n",
    "                        # Now select which arguments to pass to start protocol:\n",
    "                        print(\"Starting protocol %s on position %s\" % (protocol_identifier, pos.name))\n",
    "\n",
    "                        # Set up user specified product code if requested:\n",
    "                        if args.product_code:\n",
    "                            position_connection.device.set_user_specified_product_code(\n",
    "                                code=args.product_code\n",
    "                            )\n",
    "\n",
    "                        # Build arguments for starting protocol:\n",
    "                        basecalling_args = None\n",
    "                        if args.basecalling or args.basecall_config:\n",
    "                            barcoding_args = None\n",
    "                            alignment_args = None\n",
    "                            if args.barcode_kits or args.barcoding:\n",
    "                                barcoding_args = protocols.BarcodingArgs(\n",
    "                                    args.barcode_kits,\n",
    "                                    args.trim_barcodes,\n",
    "                                    args.barcodes_both_ends,\n",
    "                                    args.detect_mid_strand_barcodes,\n",
    "                                    args.min_score,\n",
    "                                    args.min_score_rear,\n",
    "                                    args.min_score_mid,\n",
    "                                )\n",
    "\n",
    "                            if args.alignment_reference:\n",
    "                                alignment_args = protocols.AlignmentArgs(\n",
    "                                    reference_files=[args.alignment_reference], bed_file=args.bed_file,\n",
    "                                )\n",
    "\n",
    "                            basecalling_args = protocols.BasecallingArgs(\n",
    "                                config=args.basecall_config,\n",
    "                                barcoding=barcoding_args,\n",
    "                                alignment=alignment_args,\n",
    "                            )\n",
    "\n",
    "                        read_until_args = None\n",
    "                        if args.read_until_filter:\n",
    "                            read_until_args = protocols.ReadUntilArgs(\n",
    "                                filter_type=args.read_until_filter,\n",
    "                                reference_files=[args.read_until_reference],\n",
    "                                bed_file=args.read_until_bed_file,\n",
    "                                first_channel=None,  # These default to all channels.\n",
    "                                last_channel=None,\n",
    "                            )\n",
    "\n",
    "                        def build_output_arguments(args, name):\n",
    "                            if not getattr(args, name):\n",
    "                                return None\n",
    "                            return protocols.OutputArgs(\n",
    "                                reads_per_file=getattr(args, \"%s_reads_per_file\" % name)\n",
    "                            )\n",
    "\n",
    "                        fastq_arguments = build_output_arguments(args, \"fastq\")\n",
    "                        fast5_arguments = build_output_arguments(args, \"fast5\")\n",
    "                        bam_arguments = build_output_arguments(args, \"bam\")\n",
    "\n",
    "                        # print the protocol parameters\n",
    "                        print(\"position_connection \"+str(position_connection))\n",
    "                        print(\"protocol_identifier \"+str(protocol_identifier))\n",
    "                        print(\"args.sample_id \"+str(args.sample_id))\n",
    "                        print(\"args.experiment_group \"+str(args.experiment_group))\n",
    "                        print(\"basecalling_args \"+str(basecalling_args)) \n",
    "                        print(\"read_until_args \"+str(read_until_args))\n",
    "                        print(\"fastq_arguments \"+str(fastq_arguments)) #fastq_arguments OutputArgs(reads_per_file=400)\n",
    "                        print(\"fast5_arguments \"+str(fast5_arguments)) #fast5_arguments OutputArgs(reads_per_file=400)\n",
    "                        print(\"bam_arguments \"+str(bam_arguments))\n",
    "                        print(\"args.no_active_channel_selection\"+str(args.no_active_channel_selection))\n",
    "                        print(\"args.mux_scan_period\"+str(args.mux_scan_period))\n",
    "                        print(\"args.experiment_duration \"+str(args.experiment_duration))\n",
    "                        print(\"args.extra_args \"+str(args.extra_args))  # Any extra args passed.\n",
    "\n",
    "                        # Now start the protocol:\n",
    "                        run_id = protocols.start_protocol(\n",
    "                            position_connection,\n",
    "                            protocol_identifier,\n",
    "                            sample_id=args.sample_id,\n",
    "                            experiment_group=args.experiment_group,\n",
    "                            basecalling=basecalling_args,\n",
    "                            read_until=read_until_args,\n",
    "                            fastq_arguments=fastq_arguments,\n",
    "                            fast5_arguments=fast5_arguments,\n",
    "                            bam_arguments=bam_arguments,\n",
    "                            disable_active_channel_selection=args.no_active_channel_selection,\n",
    "                            mux_scan_period=args.mux_scan_period,\n",
    "                            experiment_duration=args.experiment_duration,\n",
    "                            args=args.extra_args,  # Any extra args passed.\n",
    "                        )\n",
    "\n",
    "                        #print(\"Started protocol %s\" % run_id)\n",
    "    return errormessage+run_id # one of them should be \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9608c1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.797329Z",
     "start_time": "2021-11-22T17:46:46.779464Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def setBiasVoltage(minionId, newVoltage): # stop an existing run (if any) for a MinION device\n",
    "    manager=mkManager()\n",
    "    positions = list(manager.flow_cell_positions())\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == minionId, positions))\n",
    "    # Connect to the grpc port for the position:\n",
    "    connection = filtered_positions[0].connect()\n",
    "    v=connection.device.get_bias_voltage().bias_voltage\n",
    "    thisMessage=\"Current bias voltage: \"+str(v)+\" mV. Changing to \"+str(newVoltage)+\" mV.\"\n",
    "    connection.device.set_bias_voltage(bias_voltage=float(newVoltage))\n",
    "    v=connection.device.get_bias_voltage().bias_voltage\n",
    "    thisMessage=\"Voltage after change: \"+str(v)+\" mV.\"\n",
    "    return thisMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f18220",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.819024Z",
     "start_time": "2021-11-22T17:46:46.802512Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def stopRun(minionId): # stop an existing run (if any) for a MinION device\n",
    "    manager=mkManager()\n",
    "    positions = list(manager.flow_cell_positions())\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == minionId, positions))\n",
    "    # Connect to the grpc port for the position:\n",
    "    connection = filtered_positions[0].connect()\n",
    "    protocols = connection.protocol.list_protocol_runs()\n",
    "    bufferedRunIds = protocols.run_ids\n",
    "    thisMessage=\"No protocol running, nothing was stopped.\"\n",
    "    c=0\n",
    "    for b in bufferedRunIds:\n",
    "        try:\n",
    "            connection.protocol.stop_protocol()\n",
    "            thisMessage=\"Protocol \"+b+\" stopped on \"+minionId+\".\"\n",
    "        except:\n",
    "            c=c+1\n",
    "    return thisMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f540d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.841346Z",
     "start_time": "2021-11-22T17:46:46.824304Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# from minknow_api demos, start_seq.py\n",
    "def is_position_selected(position, args):\n",
    "    \"\"\"Find if the {position} is selected by command line arguments {args}.\"\"\"\n",
    "    if args.position == position.name: # First check for name match:\n",
    "        return True\n",
    "    connected_position = position.connect()  # Then verify if the flow cell matches:\n",
    "    if args.flow_cell_id is not None:\n",
    "        flow_cell_info = connected_position.device.get_flow_cell_info()\n",
    "        if (flow_cell_info.user_specified_flow_cell_id == args.flow_cell_id\n",
    "            or flow_cell_info.flow_cell_id == args.flow_cell_id):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71755def",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.861665Z",
     "start_time": "2021-11-22T17:46:46.847238Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getMinKnowApiStatus(deviceString): # MinKNOW status per device\n",
    "    replyString=\"\"\n",
    "    testHost=\"localhost\"\n",
    "    manager=mkManager()\n",
    "    positions = list(manager.flow_cell_positions())\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == deviceString, positions))\n",
    "    connection = filtered_positions[0].connect() # Connect to the grpc port for the position\n",
    "    # determine if anything is running and the kind of run, via set temperature\n",
    "    replyString=replyString+\"acquisition.get_acquisition_info().state: \"+str(connection.acquisition.get_acquisition_info().state)+\"<br>\"\n",
    "    replyString=replyString+\"acquisition.current_status(): \"+str(connection.acquisition.current_status())+\"<br>\"\n",
    "    replyString=replyString+\"minion_device.get_settings().temperature_target.min: \"+str(connection.minion_device.get_settings().temperature_target.min)+\"<br>\"\n",
    "    replyString=replyString+\"device.get_temperature(): \" + str(connection.device.get_temperature().minion.heatsink_temperature)+\"<br>\"\n",
    "    replyString=replyString+\"device.get_bias_voltage(): \" + str(connection.device.get_bias_voltage())+\"<br>\"\n",
    "    return replyString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e25c59d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.934549Z",
     "start_time": "2021-11-22T17:46:46.866439Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getActiveRun(deviceString):\n",
    "    manager=mkManager()\n",
    "    positions = list(manager.flow_cell_positions())\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == deviceString, positions))\n",
    "    connection = filtered_positions[0].connect() # Connect to the grpc port for the position\n",
    "    try:\n",
    "        activeRun=connection.acquisition.get_current_acquisition_run().run_id # error if no acquisition is running, same as with acquisitio.current_status(), no acquisition until temperature reached\n",
    "    except:\n",
    "        activeRun=\"none\"\n",
    "    return activeRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f541bde9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.951518Z",
     "start_time": "2021-11-22T17:46:46.939569Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getRealDeviceActivity(deviceString):            # seq. runs: 34 degC and flow cell checks 37 degC target \n",
    "    manager=mkManager()                             # temperatures seem to be the only way to determine if\n",
    "    positions = list(manager.flow_cell_positions()) # a device has been started\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == deviceString, positions))\n",
    "    connection = filtered_positions[0].connect() # Connect to the grpc port for the position\n",
    "    targetTemp=str(connection.minion_device.get_settings().temperature_target.min)\n",
    "    returnValue=\"\"\n",
    "    if targetTemp==\"34.0\":\n",
    "        returnValue=\"sequencing\"\n",
    "    elif targetTemp==\"37.0\":\n",
    "        returnValue=\"checking flow cell\"\n",
    "    elif targetTemp==\"35.0\":\n",
    "        returnValue=\"idle\"\n",
    "    return returnValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb80ef91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.968284Z",
     "start_time": "2021-11-22T17:46:46.955700Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getThisRunState(deviceString): # obtain further information about a particular device / run\n",
    "    manager=mkManager()\n",
    "    positions = list(manager.flow_cell_positions())\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == deviceString, positions))\n",
    "    connection = filtered_positions[0].connect() # Connect to the grpc port for the position\n",
    "    try:\n",
    "        thisRunState=\"Run state for \"+deviceString+\": \"\n",
    "        thisRunState=thisRunState+str(connection.protocol.get_current_protocol_run().state)+\"/\"\n",
    "        thisRunState=thisRunState+str(connection.acquisition.get_acquisition_info().state)\n",
    "    except:\n",
    "        thisRunState=\"No state information in MinKNOW buffer for \"+deviceString\n",
    "    return thisRunState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82d8fdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:46.987822Z",
     "start_time": "2021-11-22T17:46:46.974204Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getThisRunSampleID(deviceString): # get SampleID from MinKNOW by device, only available after data\n",
    "    manager=mkManager()               # acquisition as been initiated by MinKNOW.\n",
    "    positions = list(manager.flow_cell_positions())\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == deviceString, positions))\n",
    "    connection = filtered_positions[0].connect() # Connect to the grpc port for the position\n",
    "    try:\n",
    "        thisRunSampleID=connection.protocol.get_current_protocol_run().user_info.sample_id.value\n",
    "    except:\n",
    "        thisRunSampleID=\"No sampleId information in MinKNOW buffer for \"+deviceString\n",
    "    return thisRunSampleID   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13090e46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:47.004681Z",
     "start_time": "2021-11-22T17:46:46.992166Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getThisRunYield(deviceString): # get run yield by device. The data of the previous run will remain \n",
    "    manager=mkManager()            # in the buffer until acquisition (not just a start) of a new run\n",
    "    positions = list(manager.flow_cell_positions()) # have been initiated.\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == deviceString, positions))\n",
    "    connection = filtered_positions[0].connect() # Connect to the grpc port for the position\n",
    "    try:\n",
    "        acqinfo=connection.acquisition.get_acquisition_info()\n",
    "        thisRunYield=\"Run yield for \"+deviceString+\"(\"+acqinfo.run_id+\"):&nbsp;\"\n",
    "        thisRunYield=thisRunYield+str(acqinfo.yield_summary)\n",
    "    except:\n",
    "        thisRunYield=\"No yield information in MinKNOW buffer for \"+deviceString\n",
    "    return thisRunYield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646a07f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:47.026138Z",
     "start_time": "2021-11-22T17:46:47.009603Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getThisRunOutput(deviceString,sampleName,runId): # get run yield by device, sampleName, runId\n",
    "    thisRunOutput=[-1,-1] # defaults in case of error / missing information\n",
    "    manager=mkManager()            # in the buffer until acquisition (not just a start) of a new run\n",
    "    positions = list(manager.flow_cell_positions()) # have been initiated.\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == deviceString, positions))\n",
    "    connection = filtered_positions[0].connect() # Connect to the grpc port for the position\n",
    "    readCount=-3\n",
    "    calledBases=-3\n",
    "    if getThisRunSampleID(deviceString)==sampleName: # check that runID and sampleID match\n",
    "        readCount=-4\n",
    "        calledBases=-4\n",
    "        if connection.acquisition.get_current_acquisition_run().run_id==runId:\n",
    "            if connection.acquisition.current_status()!=\"status: READY\": # i.e., working\n",
    "                try:\n",
    "                    acq=connection.acquisition.get_acquisition_info()\n",
    "                    readCount=acq.yield_summary.basecalled_pass_read_count\n",
    "                    calledBases=acq.yield_summary.basecalled_pass_bases\n",
    "                except:\n",
    "                    readCount=-5\n",
    "                    calledBases=-5\n",
    "    thisRunOutput=[readCount,calledBases]\n",
    "    return thisRunOutput # shall be a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df1ce38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:47.047011Z",
     "start_time": "2021-11-22T17:46:47.032102Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getThisRunEstimatedOutput(deviceString,sampleName,runId): # get run yield by device, sampleName, runId\n",
    "    thisRunOutput=[-1,-1] # defaults in case of error / missing information\n",
    "    manager=mkManager()            # in the buffer until acquisition (not just a start) of a new run\n",
    "    positions = list(manager.flow_cell_positions()) # have been initiated.\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == deviceString, positions))\n",
    "    connection = filtered_positions[0].connect() # Connect to the grpc port for the position\n",
    "    readCount=-3\n",
    "    calledBases=-3\n",
    "    if getThisRunSampleID(deviceString)==sampleName: # check that runID and sampleID match\n",
    "        readCount=-4\n",
    "        calledBases=-4\n",
    "        if connection.acquisition.get_current_acquisition_run().run_id==runId:\n",
    "            if connection.acquisition.current_status()!=\"status: READY\": # i.e., working\n",
    "                try:\n",
    "                    acq=connection.acquisition.get_acquisition_info()\n",
    "                    readCount=acq.yield_summary.basecalled_pass_read_count\n",
    "                    calledBases=acq.yield_summary.estimated_selected_bases\n",
    "                except:\n",
    "                    readCount=-5\n",
    "                    calledBases=-5\n",
    "    thisRunOutput=[readCount,calledBases]\n",
    "    return thisRunOutput # shall be a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a863bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:47.062634Z",
     "start_time": "2021-11-22T17:46:47.052627Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def getThisRunInformation(deviceString): # get current run information. Only available after data acquisition\n",
    "    manager=mkManager()                  # has started.\n",
    "    positions = list(manager.flow_cell_positions())\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == deviceString, positions))\n",
    "    connection = filtered_positions[0].connect() # Connect to the grpc port for the position    \n",
    "    try:\n",
    "        thisRunInfo=\"Run information for \"+deviceString+\"<br><br>\"+str(connection.protocol.get_current_protocol_run())\n",
    "    except:\n",
    "        thisRunInfo=\"No protocol information in MinKNOW buffer for \"+deviceString\n",
    "    return thisRunInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef27fac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:47.082600Z",
     "start_time": "2021-11-22T17:46:47.066579Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def thisRunWatcherTerminator(deviceString,sampleName):\n",
    "    realRunId=getActiveRun(deviceString) #\n",
    "    currentBases=getThisRunEstimatedOutput(deviceString,sampleName,realRunId)[1]\n",
    "    currentBasesString=str(round(currentBases/1e6,2))\n",
    "    wantedBasesString=str(round(wantedBases/1e6,2))\n",
    "    myString=\"<html><head>\"\n",
    "    myString=myString+\"<title>\"+currentBasesString+\"/\"+wantedBasesString+\"MB:\"+sampleName+\"</title>\"\n",
    "    if currentBases < wantedBases: # don't refresh after showing the STOP state\n",
    "        myString=myString+\"<meta http-equiv='refresh' content='10'>\"\n",
    "    myString=myString+\"</head><body>\"\n",
    "    myString=myString+\"<b>Automatic run terminator</b> for sample <b>\"+sampleName+ \"</b>, run ID=\"+realRunId+\" on \"+deviceString+\" when reaching \"+wantedBasesString+\" MB, now \"+currentBasesString+\" MB\"\n",
    "    myString=myString+\"<hr>\"\n",
    "    myString=myString+\"Last refresh at \"+datetimestringnow()+\".<hr>\"\n",
    "    if currentBases > wantedBases:\n",
    "        stopRun(deviceString)\n",
    "        myString=myString+\"STOPPED at \"+datetimestringnow()\n",
    "    elif currentBases==0:\n",
    "        myString=myString+\"IDLE / MUX / ETC\"\n",
    "    else:\n",
    "        myString=myString+\"RUNNING\"\n",
    "    myString=myString+\"</body></html>\"\n",
    "    return myString"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56893e8d",
   "metadata": {},
   "source": [
    "### 3. CNV Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df7bfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:47.147180Z",
     "start_time": "2021-11-22T17:46:47.086791Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def createCNVPlot(sampleName): # create a genome-wide copy number plot (all-in-one function)\n",
    "    with tqdm(total=6) as cnvpBar:\n",
    "        cnvpBar.set_description('CNVP('+sampleName+'), loading reference data')\n",
    "        cnvpBar.update(1)\n",
    "        startTime = datetime.datetime.now()\n",
    "        runPath=nanodipOutputDir+\"/\"+sampleName\n",
    "        ChromOffsets = pandas.read_csv(chrLengthsFile, delimiter='\\t', header=None, index_col=0)\n",
    "        validChromosomes=list(ChromOffsets.index)\n",
    "        ChromOffsetCenters=[]\n",
    "        for c in range(0,len(validChromosomes)-1):\n",
    "            ChromOffsetCenters.append((ChromOffsets[2][c]+ChromOffsets[2][c+1])/2)\n",
    "        lastChromosome=len(validChromosomes)-1\n",
    "        ChromOffsetCenters.append((ChromOffsets[2][lastChromosome]+ChromOffsets[2][lastChromosome]+ChromOffsets[1][lastChromosome])/2) # last chromosome\n",
    "        centromereLocations = pandas.read_csv(centromereLocationsBed, delimiter='\\t', header=None, index_col=0)\n",
    "        centromereLocations.loc['chr1'][1]\n",
    "        centromereOffsets = []\n",
    "        for c in validChromosomes:\n",
    "            centromereOffsets.append(ChromOffsets.loc[c][2] + centromereLocations.loc[c][1])\n",
    "        cnvpBar.set_description('CNVP('+sampleName+'), loading nanopore data')\n",
    "        cnvpBar.update(1)\n",
    "        bamFiles=[] # find all bam files\n",
    "        for root, dirnames, filenames in os.walk(runPath):\n",
    "            for filename in fnmatch.filter(filenames, '*.bam'):\n",
    "                bamFiles.append(os.path.join(root, filename))\n",
    "        cnvScatter=[]\n",
    "        for thisBam in bamFiles:\n",
    "            samfile = pysam.AlignmentFile(thisBam, \"rb\") # pysam coordinates start with 0 while samtools starts with 1 ! See https://pysam.readthedocs.io/en/latest/faq.html#pysam-coordinates-are-wrong\n",
    "            for thisChromosome in validChromosomes:\n",
    "                thisChromOffset=int(ChromOffsets.loc[[thisChromosome]][2])\n",
    "                for read in samfile.fetch(thisChromosome):\n",
    "                    cnvScatter.append(read.pos+thisChromOffset)\n",
    "        #print(\"Number of reads:\"+str(len(cnvScatter)))\n",
    "        #print(max(cnvScatter)/len(cnvScatter))\n",
    "        cnvpBar.set_description('CNVP('+sampleName+'), determining bin size')\n",
    "        cnvpBar.update(1)\n",
    "        binwidth=30*max(cnvScatter)/len(cnvScatter)\n",
    "        figure(figsize=(20, 3), dpi=120)\n",
    "        xy=plt.hist(cnvScatter, bins=numpy.arange(min(cnvScatter), max(cnvScatter) + binwidth, binwidth),color=\"k\")\n",
    "        #plt.vlines(ChromOffsets[2], 0,numpy.max(xy[0]), colors='c', linestyles='solid', label='')\n",
    "        #plt.title(sampleName, fontdict=None, loc='center', pad=None)\n",
    "        #plt.yscale('log')\n",
    "        cnvpBar.set_description('CNVP('+sampleName+'), cleaning data')\n",
    "        cnvpBar.update(1)\n",
    "        plotX=xy[1][0:len(xy[0])] # exclude regions with no mapped reads from plot\n",
    "        plotY=xy[0]\n",
    "        cleanPlotX=[]\n",
    "        cleanPlotY=[]\n",
    "        for p in range(0,len(plotY)):\n",
    "            if plotY[p]>0:\n",
    "                cleanPlotX.append(plotX[p])\n",
    "                cleanPlotY.append(plotY[p])\n",
    "        cleanPlotX=numpy.array(cleanPlotX) # convert back to numpy array (required for numpy functions)\n",
    "        cleanPlotY=numpy.array(cleanPlotY)\n",
    "        yStd=numpy.std(plotY)\n",
    "        yMean=numpy.mean(plotY)\n",
    "        yMedian=numpy.median(plotY)\n",
    "        cleanCoarseX=[]     # local means, cleaned\n",
    "        cleanCoarseY=[]\n",
    "        localBinSize=int(10e6)\n",
    "        localBinStep=int(0.5e6)\n",
    "        halfLocalBinSize=localBinSize/2\n",
    "        cnvpBar.set_description('CNVP('+sampleName+'), plotting data')\n",
    "        cnvpBar.update(1)\n",
    "        for x in range(0,int(numpy.round(numpy.max(cleanPlotX))),localBinStep):\n",
    "            thisSlice=cleanPlotY[numpy.logical_and(cleanPlotX >= x,  cleanPlotX <= x+localBinSize)]\n",
    "            if len(thisSlice)>0:\n",
    "                cleanCoarseX.append(numpy.median([x,x+localBinSize]))\n",
    "                cleanCoarseY.append(numpy.median(thisSlice))\n",
    "        cleanYMedian=numpy.median(cleanPlotY)\n",
    "        cleanYLower=numpy.min(cleanPlotY)\n",
    "        cleanYUpper=yMedian*2\n",
    "        matplotlib.use('Agg')\n",
    "        figure(figsize=(20, 6), dpi=120)\n",
    "        plt.ylim(cleanYLower,cleanYUpper)\n",
    "        plt.scatter(cleanPlotX,cleanPlotY,s=0.2,color='gray',linewidths=1)\n",
    "        plt.scatter(cleanCoarseX,cleanCoarseY,s=1,linewidths=5,c=cleanCoarseY,cmap=plt.cm.coolwarm_r,vmin=cleanYLower,vmax=cleanYUpper)\n",
    "        plt.hlines(yMedian, 0, max(cleanPlotX), colors='gray', linestyles='solid', label='') # median line\n",
    "        plt.vlines(ChromOffsets[2], cleanYLower, cleanYUpper, colors='gray', linestyles='solid', label='')\n",
    "        plt.vlines(ChromOffsets[2][len(ChromOffsets[2])-1]+ChromOffsets[1][len(ChromOffsets[2])-1], cleanYLower, cleanYUpper, colors='gray', linestyles='solid', label='') # terminating vline\n",
    "        plt.vlines(centromereOffsets, cleanYLower, cleanYUpper, colors='gray', linestyles='dashed', label='')\n",
    "        plt.title(\"Sample ID: \"+sampleName, fontdict=None, loc='center', pad=None)\n",
    "        plt.xlabel('Number of mapped reads: '+str(len(cnvScatter)))\n",
    "        plt.ylabel('reads per '+ str(round(binwidth/1e6*100)/100) +' MB bin')\n",
    "        plt.xticks(ChromOffsetCenters, validChromosomes, rotation=90)\n",
    "        plt.savefig(nanodipReportDir+'/'+sampleName+'_CNVplot.png', bbox_inches='tight')\n",
    "        readCountFile = open(nanodipReportDir+'/'+sampleName+'_alignedreads.txt',\"w\")\n",
    "        readCountFile.write(str(len(cnvScatter)))\n",
    "        readCountFile.close()\n",
    "        logpr(verbosity,\"CNVP end\")\n",
    "        cnvpBar.set_description('CNVP('+sampleName+'), done')\n",
    "        cnvpBar.update(1)\n",
    "        endTime = datetime.datetime.now()\n",
    "        logpr(verbosity,\"Start: \"+str(startTime))\n",
    "        logpr(verbosity,\"End  : \"+str(endTime))\n",
    "        logpr(verbosity,\"Dur. : \"+str(endTime-startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee8210d",
   "metadata": {},
   "source": [
    "### 4. UMAP Methylation Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0176d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:47.275245Z",
     "start_time": "2021-11-22T17:46:47.152079Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def methylationUMAP(sampleName,referenceName): # create a methylation UMAP plot (all-in-one function)\n",
    "    import umap\n",
    "    startTime = datetime.datetime.now()\n",
    "    logpr(verbosity,\"UMAP Plot initiated for \"+sampleName)\n",
    "    with tqdm(total=8) as umapBar:\n",
    "        umapBar.set_description('UMAP('+sampleName+'), loading annotation')\n",
    "        umapBar.update(1)\n",
    "        binFiles=listdir(binDir) # collect reference case binary file names\n",
    "        referenceString=referenceName.replace(\".xlsx\",\"\")\n",
    "        referenceSheetFile=referenceDir+\"/\"+referenceName # load reference annotation\n",
    "        referenceSheet=openpyxl.load_workbook(referenceSheetFile)\n",
    "        referenceList = referenceSheet.active\n",
    "        col_names = []\n",
    "        sentrixID  = referenceList['A']\n",
    "        methClass  = referenceList['B']\n",
    "        customText = referenceList['C']\n",
    "        for x in range(3): \n",
    "            logpr(verbosity,sentrixID[x].value)\n",
    "            logpr(verbosity,methClass[x].value)\n",
    "            logpr(verbosity,customText[x].value)\n",
    "        indexFile=open(binIndex, \"r\") # load CpG site index file (contains index for methylation float binary data)\n",
    "        indexCol=indexFile.read().split(\"\\n\")\n",
    "        indexFile.close()\n",
    "        umapBar.set_description('UMAP('+sampleName+'), loading and processing methylation data from Nanopore run')\n",
    "        umapBar.update(1)\n",
    "        logpr(verbosity,len(indexCol))\n",
    "        methoverlapPath=nanodipOutputDir+\"/\"+sampleName # collect matching CpGs from sample\n",
    "        methoverlapTsvFiles=[] # find all *methoverlap.tsv files\n",
    "        for root, dirnames, filenames in os.walk(methoverlapPath):\n",
    "            for filename in fnmatch.filter(filenames, '*methoverlap.tsv'):\n",
    "                methoverlapTsvFiles.append(os.path.join(root, filename))\n",
    "        methoverlap=[]\n",
    "        first=True\n",
    "        for f in methoverlapTsvFiles:\n",
    "            try: # some fast5 files do not contain any CpGs\n",
    "                m = pandas.read_csv(f, delimiter='\\t', header=None, index_col=0)\n",
    "                if first:\n",
    "                    methoverlap = m\n",
    "                    first = False\n",
    "                else:\n",
    "                    methoverlap = methoverlap.append(m)\n",
    "            except:\n",
    "                logpr(verbosity,\"empty file encountered, skipping\")\n",
    "        if len(methoverlap)>0:\n",
    "            logpr(verbosity,str(\"Number of 450K overlap CpGs: \"+str(len(methoverlap))))\n",
    "            overlapProbes=methoverlap.index\n",
    "            existingProbes=set(indexCol).intersection(overlapProbes) # some probes have been skipped from the reference set, e.g. sex chromosomes\n",
    "            matching = [indexCol.index(i) for i in existingProbes]\n",
    "            logpr(verbosity,\"overlap probes in cleaned reference data: \"+str(len(matching)))\n",
    "            fileNumbers = []\n",
    "            binSuffix=\"_betas_filtered.bin\"\n",
    "            missingFiles=[] # determine if there are entries in the annotation without corresponding methylation binary file\n",
    "            c=0\n",
    "            for s in sentrixID:\n",
    "                try:\n",
    "                    fileNumbers.append(binFiles.index(s.value+binSuffix))\n",
    "                except: # e.g. file not available\n",
    "                    missingFiles.append(c)\n",
    "                c=c+1\n",
    "            logpr(verbosity,fileNumbers)\n",
    "            betaValues=numpy.full([len(matching),len(fileNumbers)],-1, dtype=float, order='C') # create an empty array with -1\n",
    "            logpr(verbosity,betaValues)\n",
    "            umapBar.set_description('UMAP('+sampleName+'), loading overlap CpGs from reference data')\n",
    "            umapBar.update(1)\n",
    "            matchJumps=numpy.full([len(matching)],-1, dtype=int, order='C')\n",
    "            matchJumps[0]=matching[0] # create jump list for binary file, add first entry\n",
    "            if len(matching)>1:\n",
    "                for m in range(1,len(matching)): # create jump distances for binary file\n",
    "                    matchJumps[m]=matching[m]-matching[m-1]-1 # concatenate to list\n",
    "            logpr(verbosity,len(matchJumps))\n",
    "            betaValues = [ [ None for y in range( len(matching) ) ] for x in range( 1 ) ]\n",
    "            p_bar = tqdm(range(len(fileNumbers))) # progress bar (development only)\n",
    "            for f in p_bar:\n",
    "                betasFilename=binDir+\"/\"+binFiles[fileNumbers[f]]\n",
    "                with open(betasFilename, 'rb') as betasFile:\n",
    "                    allBetaSingleFile = numpy.fromfile(betasFile, dtype=float) # read float with numpy into regular python array (faster) \n",
    "                    allBetaSingleFile = numpy.digitize(allBetaSingleFile,bins=[methylCutOff])\n",
    "                    betaValues.append(allBetaSingleFile[numpy.array(matching)])\n",
    "                    p_bar.set_description('UMAP('+sampleName+'), loading ref. dataset no. '+str(f))\n",
    "                betasFile.close()\n",
    "            umapBar.set_description('UMAP('+sampleName+'), merging reference and nanopore data')\n",
    "            umapBar.update(1)\n",
    "            betaValues = numpy.array(betaValues)\n",
    "            betaValues = numpy.delete(betaValues, 0, 0)\n",
    "            methoverlapNum=methoverlap.to_numpy()\n",
    "            diagnosticCaseCgs=[]\n",
    "            methoverlapCgnames=methoverlap.loc[existingProbes].index # deterine overlap CpG names\n",
    "            for i in existingProbes:\n",
    "                thisCg=numpy.mean(methoverlap.loc[[i]].values)\n",
    "                diagnosticCaseCgs.append(thisCg)\n",
    "            thisDiagnosticCase=numpy.digitize(diagnosticCaseCgs,bins=[methylCutOff]) # append the nanopore case\n",
    "            betaValues2=numpy.vstack([betaValues, thisDiagnosticCase]) # convert to numpy array for UMAP function\n",
    "            del betaValues # free memory\n",
    "            umapBar.set_description('UMAP('+sampleName+'), calculating embedding')\n",
    "            umapBar.update(1)\n",
    "            embeddingAll = umap.UMAP().fit_transform(betaValues2[:,]) # generate UMAP plot\n",
    "            logpr(verbosity,\"\\n\"+str(embeddingAll))\n",
    "            umapBar.set_description('UMAP('+sampleName+'), plotting UMAP')\n",
    "            umapBar.update(1)\n",
    "            l=len(embeddingAll)-1  # get UMAP coordinates of nanopore case (i.e., last entry in array)\n",
    "            nanoX=embeddingAll[l,0]\n",
    "            nanoY=embeddingAll[l,1]\n",
    "            selectedSentrixIds = [ binFiles[i] for i in fileNumbers]\n",
    "            logpr(verbosity,len(selectedSentrixIds))\n",
    "            selectedSentrixIds.append(sampleName)\n",
    "            logpr(verbosity,len(selectedSentrixIds))\n",
    "            annoList=[] # create an annotation list and append nanopore case as the last entry\n",
    "            c=0\n",
    "            for mc in methClass:\n",
    "                if c not in missingFiles:\n",
    "                    annoList.append(mc.value)\n",
    "                c=c+1\n",
    "            annoList.append(sampleName)\n",
    "            embeddingAll=numpy.array(embeddingAll) # convert UMAP data to numpy array\n",
    "            numberRef=str(len(embeddingAll))+\" ref. cases\"\n",
    "            numberCpG=str(len(methoverlap))+\" CpGs\"\n",
    "            umapTitle=\"UMAP for \"+sampleName+\" against \"+referenceName+\", \"+numberRef+\", \"+numberCpG\n",
    "            logpr(verbosity,type(embeddingAll))\n",
    "            logpr(verbosity,embeddingAll.shape)\n",
    "            logpr(verbosity,embeddingAll)\n",
    "            fig2 = px.scatter(x=embeddingAll[:,0], # create UMAP figure with all cases\n",
    "                              y=embeddingAll[:,1],\n",
    "                              labels={\"x\":\"UMAP 0\",\n",
    "                                      \"y\":\"UMAP 1\"},\n",
    "                              title=umapTitle, \n",
    "                              color=annoList, \n",
    "                              hover_name=selectedSentrixIds,\n",
    "                              render_mode=plotlyRenderMode) #\n",
    "            fig2.add_annotation(x=nanoX, y=nanoY,\n",
    "                                text=sampleName,\n",
    "                                showarrow=True,\n",
    "                                arrowhead=1)\n",
    "            fig2.update_yaxes(scaleanchor = \"x\", scaleratio = 1)\n",
    "            outPlot=nanodipReportDir+\"/\"+sampleName+\"_\"+referenceString+\"_UMAP_all.html\" # write to HTML file\n",
    "            fig2.write_html(outPlot)\n",
    "            fig2.write_image(nanodipReportDir+\"/\"+sampleName+\"_\"+referenceString+\"_UMAP_all.png\")    # plotly image export requires kaleido, install with pip install -U kaleido; needs reloading of plotly to take effect\n",
    "            umapBar.set_description('UMAP('+sampleName+'), calculating distance ranking')\n",
    "            umapBar.update(1)\n",
    "            distances = [] # create distance ranking\n",
    "            sentrixList = []\n",
    "            c=0\n",
    "            for s in sentrixID:\n",
    "                if c not in missingFiles:\n",
    "                    sentrixList.append(s.value)\n",
    "                c=c+1\n",
    "            sentrixList.append(\"thisCase\")\n",
    "            mcList = []\n",
    "            c=0\n",
    "            for s in methClass:\n",
    "                if c not in missingFiles:\n",
    "                    mcList.append(s.value)\n",
    "                c=c+1\n",
    "            mcList.append(\"thisCase\")\n",
    "            txtList = []\n",
    "            c=0\n",
    "            for s in methClass:\n",
    "                if c not in missingFiles:\n",
    "                    txtList.append(s.value)\n",
    "                c=c+1\n",
    "            txtList.append(\"thisCase\")\n",
    "            caseX=embeddingAll[len(embeddingAll)-1,0]\n",
    "            caseY=embeddingAll[len(embeddingAll)-1,1]\n",
    "            xList = []\n",
    "            yList = []\n",
    "            for c in embeddingAll:\n",
    "                distances.append(numpy.sqrt(numpy.power(caseX-c[0],2)+numpy.power(caseY-c[1],2))) # calculate distance\n",
    "                xList.append(c[0])\n",
    "                yList.append(c[1])\n",
    "            distanceRanking = pandas.DataFrame({'distance':distances,'methClass':mcList,'txt':txtList,\n",
    "                                                'sentrix_ID':sentrixList,'X':xList,'Y':yList})\n",
    "            distanceRanking = distanceRanking.sort_values(by='distance', axis=0, ascending=True, inplace=False, kind='quicksort')\n",
    "            # distanceRanking[0:20]\n",
    "            wb = openpyxl.Workbook()     # write plot coordinates to xlsx\n",
    "            ws = wb.active # grab the active worksheet\n",
    "            ws['A1'] = \"Sentrix_ID\"     # Data can be assigned directly to cells\n",
    "            ws['B1'] = \"X\"     \n",
    "            ws['C1'] = \"Y\"\n",
    "            for thisRow in range(len(embeddingAll)):     # Rows can also be appended\n",
    "                ws.append([selectedSentrixIds[thisRow], embeddingAll[thisRow][0], embeddingAll[thisRow][1]])\n",
    "            wb.save(nanodipReportDir+\"/\"+sampleName+\"_UMAP.xlsx\")     # Save the file\n",
    "            closeupDf=distanceRanking[0:topMatch] # generate plot of thisCase surrounding reference datasets\n",
    "            closeupList=closeupDf.values.tolist()\n",
    "            markerSize=5 # marker size for plotly\n",
    "            fig3=px.scatter(x=closeupDf[\"X\"],\n",
    "                            y=closeupDf[\"Y\"],\n",
    "                            labels={\"x\":\"UMAP 0\",\n",
    "                                    \"y\":\"UMAP 1\"},\n",
    "                            hover_name=closeupDf[\"sentrix_ID\"],\n",
    "                            title=\"Close-up \"+umapTitle,\n",
    "                            color=closeupDf[\"methClass\"],\n",
    "                            render_mode=plotlyRenderMode)\n",
    "            fig3.update_traces(marker=dict(size=markerSize))\n",
    "            fig3.add_annotation(x=nanoX, y=nanoY, text=sampleName, showarrow=True, arrowhead=1)\n",
    "            for ds in closeupDf.values.tolist(): # add transparent hyperlinks to reference CNV plots (e.g., on public EpiDiP.org server)\n",
    "                fig3.add_annotation(x=ds[4], y=ds[5],\n",
    "                                    text=\"<a href='\"+cnvLinkPrefix+ds[3]+cnvLinkSuffix+\"' target='_blank'>&nbsp;</a>\",\n",
    "                                    showarrow=False, arrowhead=1)\n",
    "            topRadius=closeupList[len(closeupList)-1][0]\n",
    "            fig3.add_shape(type=\"circle\",\n",
    "               x0=nanoX-topRadius,\n",
    "               y0=nanoY-topRadius,\n",
    "               x1=nanoX+topRadius,\n",
    "               y1=nanoY+topRadius,\n",
    "               line_color=\"black\",\n",
    "               line_width=0.5)\n",
    "            fig3.update_yaxes(scaleanchor = \"x\", scaleratio = 1)\n",
    "            outPlot=nanodipReportDir+\"/\"+sampleName+\"_\"+referenceString+\"_UMAP_top.html\"\n",
    "            fig3.write_html(outPlot)\n",
    "            fig3.write_image(nanodipReportDir+\"/\"+sampleName+\"_\"+referenceString+\"_UMAP_top.png\")\n",
    "            # create PDF-compatible HTML table with proper cell padding, no borders etc.\n",
    "            htmlTable=\"<table border=0>\"\n",
    "            htmlTable+=\"<tr><td><b>methClass</b></td><td><b>distance</b></td><td><b>txt</b></td><td><b>sentrix_ID</b></td></tr>\"\n",
    "            for i in closeupList:\n",
    "                htmlTable+=\"<tr><td>\"+str(i[1])+\"</td><td>\"+str(i[0])+\"</td><td>\"+str(i[2])+\"</td><td>\"+str(i[3])+\"</td></tr>\"\n",
    "            # generate PDF report\n",
    "            nanodipReport=\"<html><head><title>\"+sampleName+\"</title><body><h1>\"+sampleName+\"</h1>\"+sampleName+\"<br>\"+htmlTable+\"</body>\"\n",
    "            convert_html_to_pdf(nanodipReport, nanodipReportDir+\"/\"+sampleName+\"_\"+referenceString+\"_NanoDiP_ranking.pdf\")\n",
    "            cpgCountFile = open(nanodipReportDir+'/'+sampleName+'_cpgcount.txt',\"w\")\n",
    "            cpgCountFile.write(str(len(methoverlap)))\n",
    "            cpgCountFile.close()\n",
    "            logpr(verbosity,\"UMAP end\")\n",
    "            endTime = datetime.datetime.now()\n",
    "            logpr(verbosity,\"Start: \"+str(startTime))\n",
    "            logpr(verbosity,\"End  : \"+str(endTime))\n",
    "            logpr(verbosity,\"Dur. : \"+str(endTime-startTime))\n",
    "            umapBar.set_description('UMAP('+sampleName+'), completed')\n",
    "            umapBar.update(1)\n",
    "        else:\n",
    "            outPlot=nanodipReportDir+\"/\"+sampleName+\"_\"+referenceString+\"_UMAP_all.html\"\n",
    "            with open(outPlot, 'w') as txtfile:\n",
    "                txtfile.write(\"<html><body>No data to plot.</body></html>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4082952d",
   "metadata": {},
   "source": [
    "### 5. Report Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbddfcc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:47.305997Z",
     "start_time": "2021-11-22T17:46:47.282174Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generatePdfReport(sampleId,referenceId):\n",
    "    referenceName=referenceId.replace(\".xlsx\",\"\")\n",
    "    runDate=datetimestringnow()\n",
    "    runSystemName=str(socket.gethostname())\n",
    "    umapTopPlotPath=nanodipReportDir+\"/\"+sampleId+\"_\"+referenceName+\"_UMAP_top.png\"\n",
    "    cnvPlotPath=nanodipReportDir+\"/\"+sampleId+\"_CNVplot.png\"\n",
    "    readCountPath=nanodipReportDir+\"/\"+sampleId+\"_alignedreads.txt\"\n",
    "    cpgCountPath=nanodipReportDir+\"/\"+sampleId+\"_cpgcount.txt\"\n",
    "    reportPdfName=sampleId+\"_\"+referenceName+\"_NanoDiP_report.pdf\"\n",
    "    reportPdfPath=nanodipReportDir+\"/\"+reportPdfName\n",
    "    detectedBarcode=getPredominantBarcode(sampleId)\n",
    "    readCount=open(readCountPath,\"r\")\n",
    "    validReads=str(readCount.read())\n",
    "    readCount.close()\n",
    "    cpgCount=open(cpgCountPath,\"r\")\n",
    "    overlapcpgCount=str(cpgCount.read())\n",
    "    cpgCount.close()\n",
    "    htmlcode=\"\"\"\n",
    "        <html><body>\n",
    "        <h1><img src='\"\"\"+epidipLogoPath+\"\"\"' width='30' align='top'>&nbsp;&nbsp;\n",
    "        NanoDiP Report for Sample \"\"\"+sampleId+\"\"\"</h1>\n",
    "        <table border='0'>\n",
    "        <tr><td width='100'>Generated on</td><td width='10'>:</td><td>\"\"\"+runSystemName+\"\"\" / \"\"\"+runDate+\"\"\"</td></tr>\n",
    "        <tr><td>Detected barcode</td><td>:</td><td>\"\"\"+detectedBarcode+\"\"\"</td></tr>\n",
    "        <tr><td>Valid reads</td><td>:</td><td>\"\"\"+validReads+\"\"\"</td></tr>\n",
    "        <tr><td>450K overlap CpG count</td><td>:</td><td>\"\"\"+overlapcpgCount+\"\"\"</td></tr>\n",
    "        <tr><td>Reference data</td><td>:</td><td>\"\"\"+referenceName+\"\"\"</td></tr>\n",
    "        </table>\n",
    "        <h2>Methylation UMAP plot</h2>\n",
    "        <img src='\"\"\"+umapTopPlotPath+\"\"\"' width='500'><br>\n",
    "        <h2>Copy number plot</h2>\n",
    "        <img src='\"\"\"+cnvPlotPath+\"\"\"' width='700'>\n",
    "        </body><html>\n",
    "    \"\"\"\n",
    "    convert_html_to_pdf(htmlcode, reportPdfPath)\n",
    "    return \"<html><a href='reports/\"+reportPdfName+\"'>\"+\"PDF report generated for \"+sampleId+\", click this link to open it.</a></html>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f884f16f",
   "metadata": {},
   "source": [
    "### 6. User Interface Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf8f41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:47.333759Z",
     "start_time": "2021-11-22T17:46:47.311728Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def systemStats(): # obtain generic system parameters\n",
    "    total, used, free = shutil.disk_usage(minknowDataDir)\n",
    "    m=\"<tt><b>SSD or HDD usage</b><br>\"\n",
    "    m=m+\"Total: \"+str(total // (2**30))+\" GB<br>\"\n",
    "    m=m+\"Used : \"+str(used // (2**30))+\" GB<br>\"\n",
    "    m=m+\"Free : \"+str(free // (2**30))+\" GB<br>\"\n",
    "    m=m+\"<br><b>Memory</b><br>\"\n",
    "    m=m+\"free : \"+str(round(psutil.virtual_memory().available * 100 / psutil.virtual_memory().total))+\"%<br>\"\n",
    "    m=m+\"<br><b>CPU: </b><br>\"    \n",
    "    m=m+\"usage: \"+str(round(psutil.cpu_percent()))+\"%<br>\"\n",
    "    m=m+\"CpG&nbsp;&nbsp;active runs: \"+str(MinKnowIfPApi.cpgQueue)+\" <a href='resetQueue?queueName=cpg'>reset queue</a><br>\"\n",
    "    m=m+\"CNVP active runs: \"+str(MinKnowIfPApi.cnvpQueue)+\" <a href='resetQueue?queueName=cnvp'>reset queue</a><br>\"\n",
    "    m=m+\"UMAP active runs: \"+str(MinKnowIfPApi.umapQueue)+\" <a href='resetQueue?queueName=umap'>reset queue</a><br>\"\n",
    "    m=m+\"<br><br>\"\n",
    "    m=m+\"<a href='restartServer'>Restart NanoDiP</a> - <font color='#FF0000'><b>USE WITH CAUTION!</b></font>\"\n",
    "    m=m+\"</tt>\" \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6cb826",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:47.370883Z",
     "start_time": "2021-11-22T17:46:47.342105Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def analysisLaunchTable(): # present a table from which analyses can be started in a post-hoc manner\n",
    "    allowedRunFolders=[]\n",
    "    for a in getRuns():\n",
    "        for b in analysisExclude:\n",
    "            if not b in a:\n",
    "                allowedRunFolders.append(a)\n",
    "    annotations=getReferenceAnnotations()\n",
    "    lt=\"<tt><font size='-2'><table border=1>\" # lt = launch table, a HTML table with preformed commands to launch analyses\n",
    "    lt=lt+\"<thead><tr><th align='left'><b>Sample ID</b></th><th align='left'><b>CpGs</b></th><th align='left'><b>CNV</b></th>\"\n",
    "    for a in annotations:\n",
    "        lt=lt+\"<th align='left'><b>UMAP against<br>\"+a.replace(\".xlsx\", \"\")+\"</b></th>\"\n",
    "    lt=lt+\"</tr></thead><tbody>\"\n",
    "    for r in range(len(allowedRunFolders)):\n",
    "        lt=lt+\"<tr>\"\n",
    "        lt=lt+\"<td>\"+allowedRunFolders[r]+\"</td>\"\n",
    "        lt=lt+\"<td><a href='./analysisLauncher?functionName=methylationPoller&sampleName=\"+allowedRunFolders[r]+\"&refAnno=None' target='_blank' rel='noopener noreferrer' title='\"+allowedRunFolders[r]+\": CpGs'>get CpGs</a></td>\"\n",
    "        lt=lt+\"<td><a href='./analysisLauncher?functionName=cnvplot&sampleName=\"+allowedRunFolders[r]+\"&refAnno=None' target='_blank' rel='noopener noreferrer' title='\"+allowedRunFolders[r]+\": CNV'>plot CNV</a></td>\"\n",
    "        for a in annotations:\n",
    "            lt=lt+\"<td><a href='./analysisLauncher?functionName=umapplot&sampleName=\"+allowedRunFolders[r]+\"&refAnno=\"+a+\"' target='_blank' rel='noopener noreferrer' title='\"+allowedRunFolders[r]+\": \"+a.replace(\".xlsx\", \"\")+\"'>plot UMAP</a>&nbsp;\"\n",
    "            lt=lt+\"<a href='./makePdf?sampleName=\"+allowedRunFolders[r]+\"&refAnno=\"+a+\"' target='_blank' rel='noopener noreferrer' title='\"+allowedRunFolders[r]+\": \"+a.replace(\".xlsx\", \"\")+\"'>make PDF</a></td>\"    \n",
    "        lt=lt+\"</tr>\"\n",
    "    lt=lt+\"</tbody></table></font></tt>\"\n",
    "    return(lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc03cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:47.389252Z",
     "start_time": "2021-11-22T17:46:47.377757Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def listRunsTable(): # return all run folders as HTML table\n",
    "    runFoldersHtml=\"<table border=1>\"\n",
    "    for r in getRuns():\n",
    "        runFoldersHtml=runFoldersHtml+\"<tr><td>\"+r+\"</td></tr>\"\n",
    "    runFoldersHtml=runFoldersHtml+\"</table>\"\n",
    "    return(runFoldersHtml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4043eba5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:47.413574Z",
     "start_time": "2021-11-22T17:46:47.395367Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def collectPastAnalyses(): # list all analysis result files\n",
    "    fl=[] # empty file file\n",
    "    for f in listdir(nanodipReportDir):\n",
    "        for s in resultEndings:\n",
    "            if s in f:\n",
    "                fl.append([f,float(os.path.getmtime(nanodipReportDir+\"/\"+f))])\n",
    "    fl.sort(key=lambda row: (row[1], row[0]), reverse=True) # sort based on modif. date\n",
    "    fl=[j.pop(0) for j in fl] # remove date column after sorting\n",
    "    return fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc49dcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:47.434602Z",
     "start_time": "2021-11-22T17:46:47.419930Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def makePastAnalysesTable(): # create an HTML table displaying links to completed analysis results\n",
    "    ht=\"<tt><table border=1>\"\n",
    "    for f in collectPastAnalyses():\n",
    "        ht=ht+\"<tr><td><a href='reports/\"+f+\"' target='_blank' rel='noopener noreferrer'>\"+f+\"</a></td></tr>\"\n",
    "    ht=ht+\"</tt></table>\"\n",
    "    return ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695b0c7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:47.457836Z",
     "start_time": "2021-11-22T17:46:47.443417Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def livePage(deviceString): # generate a live preview of the data analysis with the current PNG figures\n",
    "    thisSampleID=getThisRunSampleID(deviceString) # if there is a run that produces data, the run ID will exist\n",
    "    thisSampleRef=readReferenceDefinition(thisSampleID).replace(\".xlsx\", \"\")\n",
    "    cnvPlotPath=\"reports/\"+thisSampleID+\"_CNVplot.png\"\n",
    "    umapAllPlotPath=\"reports/\"+thisSampleID+\"_\"+thisSampleRef+\"_UMAP_all.png\"\n",
    "    umapAllPlotlyPath=\"reports/\"+thisSampleID+\"_\"+thisSampleRef+\"_UMAP_all.html\"\n",
    "    umapTopPlotPath=\"reports/\"+thisSampleID+\"_\"+thisSampleRef+\"_UMAP_top.png\"\n",
    "    ht=\"<html><body><tt>sample ID: \"+thisSampleID+\" with reference \"+thisSampleRef+\"</tt><br>\"\n",
    "    ht=ht+\"<a href='\"+cnvPlotPath+\"' target='_blank'><img align='Top' src='\"+cnvPlotPath+\"' width='50%' alt='CNV plot will appear here'></a>\"\n",
    "    ht=ht+\"<a href='\"+umapAllPlotlyPath+\"' target='_blank'><img align='Top' src='\"+umapAllPlotPath+\"' width='50%' alt='UMAP plot will appear here'></a>\"\n",
    "    ht=ht+\"</tt></table><body></html>\"\n",
    "    return ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b2410",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:47.474359Z",
     "start_time": "2021-11-22T17:46:47.464426Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def methcallLivePage(sampleName): # generate a self-refreshing page to invoke methylation calling\n",
    "    ht=\"<html><head><title>MethCaller: \"+sampleName+\"</title>\"\n",
    "    ht=ht+\"<meta http-equiv='refresh' content='3'></head><body>\"\n",
    "    ht=ht+\"last refresh and console output at \"+datetimestringnow()+\"<hr>shell output<br><br><tt>\"\n",
    "    #ht=ht+calculateMethylationAndBamFromFast5Fastq(sampleName)\n",
    "    ht=ht+f5cOneFast5(sampleName,analyzeOne=True)\n",
    "    ht=ht+\"</tt></body></html>\"\n",
    "    return ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deaec75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:46:47.501351Z",
     "start_time": "2021-11-22T17:46:47.480538Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def menuheader(n,r): # generate a universal website header for the UI pages that contains a simple main menu\n",
    "    menuList=[[\"index\",\"Overview\",\"General system information\"],\n",
    "              [\"listPositions\",\"Mk1b Status\",\"Live status of all connected Mk1b devices\"],\n",
    "              [\"startSequencing\",\"Start seq.\",\"Start a sequencing run on an idle Mk1b device\"],\n",
    "              [\"startTestrun\",\"Start test run\",\"Start a test seq. run on an idle Mk1b device to verify that the previous flow cell wash was successful.\"],\n",
    "              [\"listExperiments\",\"Seq. runs\",\"List all buffered runs. Will be purged upon MinKNOW backend restart.\"],\n",
    "              [\"listRuns\",\"Results\",\"List all completed analysis results\"],\n",
    "              [\"analyze\",\"Analyze\",\"Launch data analyses manually, e.g. for retrospective analysis\"],\n",
    "              [\"about\",\"About NanoDiP\",\"Version, etc.\"]\n",
    "             ]\n",
    "    mm=\"<html><head><title>NanoDiP Version \"+versionString+\"</title>\"\n",
    "    if r>0: # autorefresh wanted\n",
    "        mm=mm+\"<meta http-equiv='refresh' content='\"+str(r)+\"'>\"\n",
    "    mm=mm+'''</head><body><table border=0 cellpadding=2><tr>\n",
    "    <td><img src='img/EpiDiP_Logo_01.png' width='40px' height='40px'></td>'''\n",
    "    nn=0\n",
    "    for m in menuList:\n",
    "        if n==nn:\n",
    "            selectedColor=\"#E0E0E0\"\n",
    "        else:\n",
    "            selectedColor=\"white\"\n",
    "        mm=mm+\"<td bgcolor='\"+selectedColor+\"'><b><a href='\"+m[0]+\"' title='\"+m[2]+\"'>\"+m[1]+\"</a></b></td>\"\n",
    "        nn=nn+1\n",
    "    mm=mm+\"</tr></table><br>\"\n",
    "    return(mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56115ba4",
   "metadata": {},
   "source": [
    "### 6. CherryPy Web UI\n",
    "The browser-based user interface is based on CherryPy, which contains an intergrated web server and serves pages locally. Communication between the service and browser typically generates static web pages that may or may not contain automatic self refresh commands. In the case of self-refreshing pages, the browser will re-request a given page with leads to re-execution of the respective python functions. The main handles to these function are located in the Web UI cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83803b86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T17:48:37.495294Z",
     "start_time": "2021-11-22T17:46:47.508726Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Launch CherryPy Webserver. Relaunch this cell only unless other cells have been modified to restart.\n",
    "class MinKnowIfPApi(object): # the CherryPy Web UI class that defines entrypoints and function calls\n",
    "    # global variables within the CherryPy Web UI\n",
    "    globalRunFolders=getRuns()\n",
    "    globalRunStatus= [None] * len(globalRunFolders)\n",
    "    cpgQueue=0\n",
    "    umapQueue=0\n",
    "    cnvpQueue=0\n",
    "    \n",
    "    @cherrypy.expose\n",
    "    def index(self):\n",
    "        myString=menuheader(0,15)\n",
    "        myString=myString+\"<tt><b>Computer:</b> \"+str(socket.gethostname())+\"</tt><br><br>\"\n",
    "        myString=myString+systemStats()\n",
    "        return myString\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def restartServer(self):\n",
    "        myString=menuheader(0,15)\n",
    "        myString=myString+\"NanoDiP server is restarting. It may be necesscary to reload some tabs to resume operation. Click on a menu item to proceed.\"\n",
    "        restartNanoDiP()\n",
    "        return myString\n",
    "    \n",
    "    @cherrypy.expose\n",
    "    def resetQueue(self,queueName=\"\"):\n",
    "        myString=menuheader(0,15)\n",
    "        if queueName:\n",
    "            if queueName==\"cpg\":\n",
    "                MinKnowIfPApi.cpgQueue=0\n",
    "            if queueName==\"umap\":\n",
    "                MinKnowIfPApi.umapQueue=0\n",
    "            if queueName==\"cnvp\":\n",
    "                MinKnowIfPApi.cnvpQueue=0\n",
    "            myString=myString+queueName+\" queue reset\"\n",
    "        return myString\n",
    "    \n",
    "    @cherrypy.expose\n",
    "    def listPositions(self):      \n",
    "        myString=menuheader(1,10)\n",
    "        positions=listMinionPositions()\n",
    "        for pos in positions:\n",
    "            n=str(pos.name) # pos.state does not tell much other than that the device is connected with USB (\"running\")\n",
    "            myString=myString+\"<br><iframe src='DeviceStatusLive?deviceString=\"+n+\"' height='200' width='600' title='\"+n+\"' border=3></iframe>\"\n",
    "            myString=myString+\"<iframe src='AnalysisStatusLive?deviceString=\"+n+\"' height='200' width='600' title='\"+n+\"' border=3></iframe>\"\n",
    "            myString=myString+\"<br><a href='DeviceStatusLive?deviceString=\"+n+\"' target='_blank' title='Click to open device status page in new tab or window'>\"+n+\"</a>\"\n",
    "            myString=myString+\", live state: \"+getRealDeviceActivity(n)\n",
    "            activeRun=getActiveRun(n)\n",
    "            myString=myString+\", active run: \"+getActiveRun(n)\n",
    "            if activeRun!=\"none\":\n",
    "                myString=myString+\" <a href='launchAutoTerminator?sampleName=\"+getThisRunSampleID(n)+\"&deviceString=\"+n+\"' target='_blank'>\"\n",
    "                myString=myString+\"<br>Click this link to launch automatic run terminator after \"+str(round(wantedBases/1e6))+\" MB.</a>\"\n",
    "                myString=myString+\"<br><font color=''#ff0000'><a href='stopSequencing?deviceId=\"+n+\"' title='Clicking this will terminate the current run immediately! Use with care!'>terminate manually</a></font>\"\n",
    "            myString=myString+\"<br><br>\"\n",
    "        myString=myString+\"</body></html>\"\n",
    "        return myString\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def startSequencing(self,deviceId=\"\",sampleId=\"\",runDuration=\"\",referenceFile=\"\",startBiasVoltage=\"\"):\n",
    "        myString=menuheader(2,0)\n",
    "        if sampleId:\n",
    "            if float(runDuration)>=0.1:\n",
    "                sys.argv = ['',\n",
    "                            '--host','localhost',\n",
    "                            '--position',deviceId,\n",
    "                            '--sample-id',sampleId,\n",
    "                            '--experiment-group',sampleId,\n",
    "                            '--experiment-duration',runDuration,\n",
    "                            '--basecalling',\n",
    "                            '--fastq',\n",
    "                            '--fastq-reads-per-file',readsPerFile,\n",
    "                            '--fast5',\n",
    "                            '--fast5-reads-per-file',readsPerFile,\n",
    "                            '--verbose',\n",
    "                            '--kit','SQK-RBK004',\n",
    "                            '--barcoding',\n",
    "                            '--barcode-kits','SQK-RBK004',\n",
    "                            '--','--start_bias_voltage',startBiasVoltage] # The \"--\" are required for so-called extra-arguments.\n",
    "                realRunId=startRun()\n",
    "                writeReferenceDefinition(sampleId,referenceFile)\n",
    "                myString=myString+\"sequencing run started for \"+sampleId+\" on \"+deviceId+\" as \"+realRunId+\" with reference \"+referenceFile\n",
    "                myString=myString+\"<hr>\"+getThisRunInformation(deviceId)\n",
    "                myString=myString+'''<hr>Navigate to <b>MK1b Status</b> to launch the run terminator. It may take several minutes until the link for the\n",
    "                run terminator appears. This is due to the inexistent run state while the flow cell is being heated up to operation temperature.\n",
    "                In addition, you may want to navigate to <b>Analyze</b> and launch <b>get CpGs</b>.<br><br>\n",
    "                If you do not start the run terminator, you will have to terminate the run manually, or it will stop after the predefined time.'''\n",
    "        else:    \n",
    "            myString=myString+'''<form action=\"startSequencing\" method=\"GET\">\n",
    "                Select an idle Mk1b:&nbsp;<select name=\"deviceId\" id=\"deviceId\">'''\n",
    "            positions=listMinionPositions()\n",
    "            for pos in positions:\n",
    "                thisPos=pos.name\n",
    "                if getRealDeviceActivity(thisPos)==\"idle\":\n",
    "                    if getFlowCellID(thisPos)!=\"\":\n",
    "                        myString=myString+'<option value=\"'+thisPos+'\">'+thisPos+': '+getFlowCellID(thisPos)+'</option>'\n",
    "            myString=myString+'''\n",
    "                </select>&nbsp; and enter the sample ID:&nbsp;<input type=\"text\" name=\"sampleId\" />\n",
    "                &nbsp;with start voltage&nbsp;<select name=\"startBiasVoltage\" id=\"startBiasVoltage\">'''\n",
    "            for vo in range(-180,-260,-5):\n",
    "                myString=myString+'<option value=\"'+str(vo)+'\">'+str(vo)+' mV</option>'\n",
    "            myString=myString+'''</select>\n",
    "                &nbsp;for&nbsp;<input type=\"text\" name=\"runDuration\" value=\"72\" />&nbsp;hours.\n",
    "                &nbsp;Reference set&nbsp;<select name=\"referenceFile\" id=\"referenceFile\">'''\n",
    "            for ref in getReferenceAnnotations():\n",
    "                myString=myString+'<option value=\"'+ref+'\">'+ref+'</option>'\n",
    "            myString=myString+'&nbsp;<input type=\"submit\" value=\"start sequencing now\"/></form>'\n",
    "        return myString\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def startTestrun(self,deviceId=\"\"):\n",
    "        myString=menuheader(3,0)\n",
    "        if deviceId:\n",
    "            sampleId=datetimestringnow()+\"_TestRun_\"+getFlowCellID(deviceId)\n",
    "            sys.argv = ['',\n",
    "                        '--host','localhost',\n",
    "                        '--position',deviceId,\n",
    "                        '--sample-id',sampleId,\n",
    "                        '--experiment-group',sampleId,\n",
    "                        '--experiment-duration','0.1',\n",
    "                        '--basecalling',\n",
    "                        '--fastq',\n",
    "                        '--fastq-reads-per-file',readsPerFile,\n",
    "                        '--fast5',\n",
    "                        '--fast5-reads-per-file',readsPerFile,\n",
    "                        '--verbose',\n",
    "                        '--kit','SQK-RBK004',\n",
    "                        '--barcoding',\n",
    "                        '--barcode-kits','SQK-RBK004',\n",
    "                        '--','--start_bias_voltage','180'] # The \"--\" are required for so-called extra-arguments. For test runs, the default -180 mV are ok.\n",
    "            realRunId=startRun()\n",
    "            myString=myString+\"sequencing run started for \"+sampleId+\" on \"+deviceId+\" as \"+realRunId\n",
    "            myString=myString+\"<hr>\"+getThisRunInformation(deviceId)\n",
    "        else:    \n",
    "            myString=myString+'''<form action=\"startTestrun\" method=\"GET\">\n",
    "                Select an idle Mk1b:&nbsp;<select name=\"deviceId\" id=\"deviceId\">'''\n",
    "            positions=listMinionPositions()\n",
    "            for pos in positions:\n",
    "                thisPos=pos.name\n",
    "                if getRealDeviceActivity(thisPos)==\"idle\":\n",
    "                    if getFlowCellID(thisPos)!=\"\":\n",
    "                        myString=myString+'<option value=\"'+thisPos+'\">'+thisPos+': '+getFlowCellID(thisPos)+'</option>'\n",
    "            myString=myString+'''\n",
    "                </select>&nbsp;<input type=\"submit\" value=\"start test run now (0.1h)\"/></form>'''\n",
    "        return myString\n",
    "    \n",
    "    @cherrypy.expose\n",
    "    def stopSequencing(self,deviceId=\"\"):      \n",
    "        myString=menuheader(1,0)\n",
    "        myString=myString + stopRun(deviceId)\n",
    "        myString=myString + \"<br><br>Click on any menu item to proceed.\"\n",
    "        return myString\n",
    "    \n",
    "    @cherrypy.expose\n",
    "    def changeVoltageLive(self,deviceId=\"\",newVoltage=\"\"):      \n",
    "        myString=menuheader(1,0)\n",
    "        myString=myString + setBiasVoltage(deviceId,newVoltage)\n",
    "        myString=myString + \"<br><br>Click on any menu item to proceed.\"\n",
    "        return myString\n",
    "    \n",
    "    @cherrypy.expose\n",
    "    def listExperiments(self):\n",
    "        myString=menuheader(4,10)\n",
    "        myString=myString+\"Running and buffered experiments:<br>\"\n",
    "        experiments=listMinionExperiments()\n",
    "        myString=myString+experiments\n",
    "        return myString \n",
    "    \n",
    "    @cherrypy.expose\n",
    "    def listRuns(self):\n",
    "        myString=menuheader(5,0)\n",
    "        myString=myString+makePastAnalysesTable()\n",
    "        return myString    \n",
    "      \n",
    "    @cherrypy.expose\n",
    "    def analyze(self):\n",
    "        myString=menuheader(6,0)        \n",
    "        myString=myString+analysisLaunchTable()\n",
    "        return myString\n",
    " \n",
    "    @cherrypy.expose\n",
    "    def cnvplot(self, sampleName=None):\n",
    "        myString=\"\"\n",
    "        if sampleName:\n",
    "            while MinKnowIfPApi.cnvpQueue>0:\n",
    "                time.sleep(2)\n",
    "            MinKnowIfPApi.cnvpQueue+=1\n",
    "            try:\n",
    "                createCNVPlot(sampleName)\n",
    "                errorString=\"\"\n",
    "            except:\n",
    "                errorString=\"<b><font color='#FF0000'>ERROR OCCURRED, PLEASE RELOAD TAB</font></b>\"\n",
    "            myString=\"<html><head><title>\"+sampleName+\" at \"+datetimestringnow()+\"</title></head><body>\"\n",
    "            myString=myString+errorString\n",
    "            myString=myString+\"<img src='reports/\"+sampleName+\"_CNVplot.png' width='100%'>\"\n",
    "            myString=myString+\"</body></html>\"\n",
    "            MinKnowIfPApi.cnvpQueue-=1\n",
    "        return myString\n",
    "    \n",
    "    @cherrypy.expose\n",
    "    def umapplot(self, sampleName=None, refAnno=None):\n",
    "        myString=\"\"\n",
    "        if sampleName and refAnno:\n",
    "            while MinKnowIfPApi.umapQueue>0:\n",
    "                time.sleep(2)\n",
    "            MinKnowIfPApi.umapQueue+=1\n",
    "            refAnnoName=refAnno.replace(\".xlsx\",\"\")\n",
    "            try:\n",
    "                methylationUMAP(sampleName,refAnno)\n",
    "                errorString=\"\"\n",
    "            except:\n",
    "                errorString=\"<b><font color='#FF0000'>ERROR OCCURRED, PLEASE RELOAD TAB</font></b>\"\n",
    "            myString=\"<html><head><title>\"+sampleName+\" against \"+refAnno+\" at \"+datetimestringnow()+\"</title>\"\n",
    "            myString=myString+\"<meta http-equiv='refresh' content='1; URL=reports/\"+sampleName+\"_\"+refAnnoName+\"_UMAP_all.html'>\"\n",
    "            myString=myString+\"</head><body>\"\n",
    "            myString=myString+errorString\n",
    "            myString=myString+\"Loading UMAP plot. It it fails, <a href='reports/\"+sampleName+\"_\"+refAnnoName+\"_UMAP_all.html'>click here to load plot</a>.\"\n",
    "            myString=myString+\"</body></html>\"\n",
    "            MinKnowIfPApi.umapQueue-=1\n",
    "        return myString\n",
    "    \n",
    "    @cherrypy.expose\n",
    "    def makePdf(self, sampleName=None, refAnno=None):    \n",
    "        myString=\"\"\n",
    "        if sampleName and refAnno:\n",
    "            myString=generatePdfReport(sampleName,refAnno)\n",
    "        return myString\n",
    "    \n",
    "    @cherrypy.expose\n",
    "    def about(self):\n",
    "        myString=menuheader(7,0)+'''\n",
    "        <b>NanoDiP</b> is a tool to obtain and analyze low-coverage whole genome\n",
    "        nanopore sequencing information through bascalling, genomic alignment,\n",
    "        copy number extrapolation, and unsupervised machine learning by UMAP-based\n",
    "        dimensions reduction. It is the nanopore-centered implementation of\n",
    "        <a href=\"http://www.epidip.org\">EpiDiP</a> which stands for <i>Epigenomic\n",
    "        Digital Pathology</i>. NanoDiP hence abbreviates <i>Nanopore\n",
    "        Digital Pathology</i>.<br><br>\n",
    "        Nanopore sequencing is developed and sold by <a href=\"https://nanoporetech.com/\">ONT</a>.\n",
    "        Then authors of this software are not affiliated with ONT.<br><br>\n",
    "        This software is licensed under the \n",
    "        <a href=\"https://www.gnu.org/licenses/gpl-3.0.html\">GPLv3</a>. By using this\n",
    "        program, you agree to the terms specified herein.<br><br>\n",
    "        <b>This software is not a medical device.</b> Its use occurs in the sole responsibility\n",
    "        of the treating physician. The authors shall not be held liable for any\n",
    "        damage caused by this software. \n",
    "        <b>Basic understanding of how this system works and internal validation are \n",
    "        strongly advised before implementation in a diagnostic setting.</b>\n",
    "        '''\n",
    "        return myString  \n",
    "    \n",
    "    @cherrypy.expose\n",
    "    def DeviceStatusLive(self,deviceString=\"\"):\n",
    "        currentFlowCellId=getFlowCellID(deviceString)\n",
    "        myString=\"<html><head><title>\"+deviceString+\": \"+currentFlowCellId+\"</title>\"\n",
    "        try:\n",
    "            myString=myString+\"<meta http-equiv='refresh' content='2'>\"\n",
    "            if getRealDeviceActivity(deviceString)==\"sequencing\":\n",
    "                myString=myString+\"<body bgcolor='#00FF00'>\"\n",
    "            else:\n",
    "                myString=myString+\"<body>\"\n",
    "            myString=myString+\"<b>\"+deviceString+\": \"+currentFlowCellId+\"</b><br><tt>\"\n",
    "            myString=myString+getMinKnowApiStatus(deviceString)\n",
    "        except:\n",
    "            myString=myString+\"<br>No previous device activity, information will appear as soon as the device has been running once in this session.<br>\"\n",
    "        myString=myString+\"Sample ID: \"+getThisRunSampleID(deviceString)+\"<br>\"\n",
    "        myString=myString+getThisRunState(deviceString)\n",
    "        myString=myString+\"<br>\"+getThisRunYield(deviceString)\n",
    "        myString=myString+\"</tt></body></html>\"\n",
    "        return myString\n",
    "    \n",
    "    @cherrypy.expose\n",
    "    def AnalysisStatusLive(self,deviceString=\"\"):\n",
    "        myString=\"\"\n",
    "        if deviceString:\n",
    "            myString=livePage(deviceString)\n",
    "        return myString\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def analysisLauncher(self,functionName=\"\",sampleName=\"\",refAnno=\"\"):\n",
    "        if functionName and sampleName and refAnno:\n",
    "            myString=\"<html><head><title>\"+sampleName+\" \"+functionName+\"</title></head><body>\"\n",
    "            myString=myString+functionName+\" launched for \"+sampleName+\" \"\n",
    "            if refAnno!=\"None\":\n",
    "                myString=myString+\"against \"+refAnno\n",
    "            myString=myString+\" at \"+datetimestringnow()+\". \"\n",
    "            myString=myString+\"Frame below will display result upon completion, if this tab/window is kept open.\"\n",
    "            if refAnno==\"None\":\n",
    "                myString=myString+\"<br><iframe src='./\"+functionName+\"?sampleName=\"+sampleName+\"' height='95%' width='100%' title='\"+sampleName+\"' border=3></iframe>\"\n",
    "            else:\n",
    "                myString=myString+\"<br><iframe src='./\"+functionName+\"?sampleName=\"+sampleName+\"&refAnno=\"+refAnno+\"' height='95%' width='100%' title='\"+sampleName+\"' border=3></iframe>\"\n",
    "        else:\n",
    "            myString=\"Nothing to launch. You may close this tab now.\"\n",
    "        return myString\n",
    "    \n",
    "    @cherrypy.expose\n",
    "    def analysisPoller(self,sampleName=\"\",deviceString=\"\",runId=\"\"):\n",
    "        myString=\"<html><head>\"\n",
    "        if sampleName and deviceString and runId:\n",
    "                myString=myString+\"<title>Poller: \"+sampleName+\"/\"+deviceString+\"/\"+runId+\"</title>\"\n",
    "                myString=myString+\"<meta http-equiv='refresh' content='15'>\"\n",
    "                myString=myString+\"<body>\"\n",
    "                myString=myString+\"Last refresh for \"+sampleName+\"/\"+deviceString+\"/\"+runId+\" at \"+datetimestringnow()\n",
    "                myString=myString+\"</body></html>\"\n",
    "                writeRunTmpFile(sampleName,deviceString)\n",
    "        return myString\n",
    "    \n",
    "    @cherrypy.expose\n",
    "    def methylationPoller(self,sampleName=\"\"):\n",
    "        while MinKnowIfPApi.cpgQueue>0:\n",
    "            time.sleep(2)\n",
    "        MinKnowIfPApi.cpgQueue+=1\n",
    "        myString=methcallLivePage(sampleName)\n",
    "        MinKnowIfPApi.cpgQueue-=1\n",
    "        return myString\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def launchAutoTerminator(self,sampleName=\"\",deviceString=\"\"):\n",
    "        myString=\"ERROR\"\n",
    "        if sampleName and deviceString:\n",
    "            myString=thisRunWatcherTerminator(deviceString,sampleName)\n",
    "        return myString\n",
    "    \n",
    "# CherryPy server configuration\n",
    "config = {  \n",
    "    'global' : {\n",
    "        'server.socket_host' : cherrypyHost,\n",
    "        'server.socket_port' : cherrypyPort,\n",
    "        'server.thread_pool' : cherrypyThreads,\n",
    "        'response.timeout' : 10,\n",
    "        'server.shutdown_timeout': 1 \n",
    "              }\n",
    "}\n",
    "# Start CherryPy Webserver\n",
    "if debugLogging==True:\n",
    "    cherrypy.log.screen=True #set access logging\n",
    "    cherrypy.config.update({'log.screen': True})\n",
    "else:\n",
    "    cherrypy.log.screen=False #set access logging\n",
    "    cherrypy.config.update({'log.screen': False})\n",
    "    cherrypy.config.update({ \"environment\": \"embedded\" })\n",
    "print(\"NanoDiP server running at http://\"+cherrypyHost+\":\"+str(cherrypyPort))\n",
    "if __name__ == '__main__':\n",
    "#    cherrypy.tree.mount(root, '/', config=config) \n",
    "    cherrypy.quickstart(MinKnowIfPApi(),\n",
    "                        '/',\n",
    "                        {'/favicon.ico':\n",
    "                         {'tools.staticfile.on':True,\n",
    "                          'tools.staticfile.filename':\n",
    "                          thisFaviconPath},\n",
    "                        '/img':\n",
    "                         {'tools.staticdir.on': True,\n",
    "                          'tools.staticdir.dir': \n",
    "                          imgPath},\n",
    "                        '/reports':\n",
    "                         {'tools.staticdir.on': True,\n",
    "                          'tools.staticdir.dir': \n",
    "                          nanodipReportDir}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce79fec",
   "metadata": {},
   "source": [
    "### ^^^ LIVE LOG ABOVE ^^^ \n",
    "All CherryPy access will be logged here, including live progress bars for computationally intense analyses. Detailed access logging is turned off by default (accessLogging is False), but can be turned on,e.g., for debugging, in the configuration section at the beginning of this notebook. While it is not required to have at look at these during normal operation, information contained in the log may be helpful in troubleshooting. Line numbers in error messages indicated here typically match those given in the respective Jupyter Notebook cells.\n",
    "\n",
    "To preseve these messages, halt the Python kernel, save and close the notebook to send it for support. This makes sure that the code as well as the error messages will be preserved.\n",
    "\n",
    "To launch the user interface, wait until you see a pink log entry that the web server has started, then navigate to http://localhost:8080."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
